{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### CSCI 303\n",
    "# Introduction to Data Science\n",
    "<p/>\n",
    "### 7 - Machine Learning Beginnings (2)\n",
    "\n",
    "![Bias-variance tradeoff](bias-variance.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Lecture\n",
    "---\n",
    "- Some more basic supervised learning concepts\n",
    "- Some more Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From Last Time\n",
    "---\n",
    "Recall from last time, we generated noisy data samples from this function:\n",
    "\n",
    "$$ f(x) = 3 + 0.5 n - n^2 + 0.15 n^3 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before we go any further, let's introduce Python *functions* to make our life a bit easier.\n",
    "\n",
    "Here's $f(x)$ as a Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 + 0.5 * x - x**2 + 0.15 * x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python functions have very flexible parameter lists and are first class objects, making them very powerful and useful.  We'll explore these concepts as they become relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we can compute $f(x)$ and plot it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "X = np.arange(-5, 5, 0.1)\n",
    "Y = f(X)\n",
    "\n",
    "plt.plot(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We also want $n$ sample points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "\n",
    "np.random.seed(12345)  # just for repeatability of this lecture\n",
    "\n",
    "def sample(n, fn, limits, noise=1):\n",
    "    width = limits[1] - limits[0]\n",
    "    x = np.random.random(n) * width + limits[0]\n",
    "    y = fn(x) + np.random.randn(n) * noise\n",
    "    return x, y\n",
    "\n",
    "# note we can pass in f as an object, and use it in sample!\n",
    "trainX, trainY = sample(n, f, [-5, 5], 3)\n",
    "\n",
    "plt.plot(X, Y, 'b-', trainX, trainY, 'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our approximation model using linear regression looks like:\n",
    "$$\\begin{align}\n",
    "    \\hat f(\\mathbf{x}) & = 1 w_0 + x_1 w_1 + ... + x_k w_k \\\\\n",
    "                   & = \\phi \\cdot \\mathbf{w}\n",
    "  \\end{align}$$\n",
    "  \n",
    "where $\\phi$ is a vector of *features* of the input X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our input is simple: just an x coordinate.\n",
    "\n",
    "So we generated some richer features using powers of X.\n",
    "\n",
    "For flexibility, let's implement $\\phi$ as a function of X, with a parameter that lets us tune the model complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def phi(x, k):\n",
    "    return np.array([x ** p for p in range(k+1)]).T\n",
    "\n",
    "Phi = phi(trainX, 5)\n",
    "#Phi.shape\n",
    "Phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And then we learned a function approximation using using OLS regression:\n",
    "\n",
    "$$ \\mathbf{w} = (\\Phi^T \\Phi)^{-1} \\Phi^T \\mathbf{y} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsq(A, b):\n",
    "    return np.linalg.inv(A.T @ A) @ A.T @ b\n",
    "\n",
    "w = lsq(Phi, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plotting our learned function in the range [-5, 5]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat = phi(X, 5) @ w\n",
    "plt.plot(X, Y, 'b-', trainX, trainY, 'k.', X, Yhat, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error Measures\n",
    "---\n",
    "The above picture is nice, but what does it actually tell us about the quality of our approximation?\n",
    "\n",
    "How can we tell if a different model actually is a better \"fit\"?\n",
    "\n",
    "We need a *measure* of the quality of the fit to usefully compare different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## MSE and RMSE\n",
    "---\n",
    "Mean Squared Error (MSE) is the variance of our data with respect to our approximation:\n",
    "\n",
    "$$ MSE = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\hat f(x_i))^2 $$\n",
    "\n",
    "RMSE is just the square root of the MSE (cf. standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Doing the math, we can see that MSE and RMSE for our fit are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "diff = trainY - (Phi @ w)\n",
    "\n",
    "MSE = (diff ** 2).sum() / n\n",
    "RMSE = math.sqrt(MSE)\n",
    "\n",
    "print(\"MSE:  \", MSE)\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpreting (R)MSE\n",
    "---\n",
    "What is our error measure telling us?\n",
    "\n",
    "- Roughly, the error we expect to have on any training point\n",
    "\n",
    "Is this useful?  Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Comparison\n",
    "---\n",
    "Can we reduce RMSE with more features?\n",
    "\n",
    "Yes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model with powers of x up to x**10\n",
    "Phi10 = phi(trainX, 10)\n",
    "w10 = lsq(Phi10, trainY)\n",
    "\n",
    "# make RMSE calc into a function for easier use\n",
    "def rmse(y, yhat):\n",
    "    return math.sqrt(((yhat - y) ** 2).sum() / len(y))\n",
    "\n",
    "# measure RMSE\n",
    "RMSE10 = rmse(trainY, Phi10 @ w10)\n",
    "\n",
    "print(\"RMSE (order 5): \", RMSE)\n",
    "print(\"RMSE (order 10):\", RMSE10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visualize this clearly improved approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat10 = phi(X, 10) @ w10\n",
    "plt.plot(X, Y, 'b-', trainX, trainY, 'k.', X, Yhat10, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training vs Testing\n",
    "---\n",
    "Above we computed the *training* error:\n",
    "\n",
    "- Tells us about our approximation power\n",
    "- Doesn't really tell us about prediction quality!\n",
    "\n",
    "We need a way to test performance on previously unseen data!\n",
    "\n",
    "- Typically hold out some data points as a *test set*\n",
    "- Measure RMSE on test set to compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# draw test samples from same function/noise \n",
    "# distribution as training data\n",
    "testX, testY = sample(20, f, [-5, 5], 3)\n",
    "\n",
    "# compute RMSEs on test data\n",
    "testPhi = phi(testX, 5)\n",
    "testPhi10 = phi(testX, 10)\n",
    "\n",
    "testRMSE = rmse(testY, testPhi @ w)\n",
    "testRMSE10 = rmse(testY, testPhi10 @ w10)\n",
    "\n",
    "print(\"test RMSE (order 5): \", testRMSE)\n",
    "print(\"test RMSE (order 10):\", testRMSE10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overfitting (and Underfitting)\n",
    "---\n",
    "The above example demonstrates a classic supervised learning problem known as *overfitting*.\n",
    "\n",
    "Overfitting is also known as \"fitting the noise\".\n",
    "\n",
    "Essentially, we can push down training error indefinitely simply by cranking up model complexity.\n",
    "\n",
    "However, *test* error starts increasing at some point.  We can plot this trend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainRMSE = []\n",
    "testRMSE = []\n",
    "orders = range(1, 13)\n",
    "\n",
    "for p in orders:\n",
    "    w = lsq(phi(trainX, p), trainY)\n",
    "    trainRMSE.append(rmse(trainY, phi(trainX, p) @ w))\n",
    "    testRMSE.append(rmse(testY, phi(testX, p) @ w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(orders, trainRMSE, 'r-o', orders, testRMSE, 'b-s')\n",
    "plt.xlabel('order')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend(['Training', 'Test'], loc=\"upper center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The U-shaped blue curve is a pretty classic illustration of overfitting.\n",
    "\n",
    "This is sometimes called a \"bathtub\" plot due to the shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also visualize each of the fits, if desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in orders:\n",
    "    w = lsq(phi(trainX, p), trainY)\n",
    "    Yhat = phi(X, p) @ w\n",
    "    plt.subplot(3, 4, p)\n",
    "    plt.plot(X, Y, 'b:', X, Yhat, 'r-')\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.title('order ' + str(p))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later we'll explore techniques for finding the \"best fit\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias and Variance\n",
    "---\n",
    "Mathematically, the *expected MSE* for a test input $x$ can be decomposed into three sources of error:\n",
    "\n",
    "- The **variance** of $\\hat f(x)$\n",
    "- The **squared bias** of $\\hat f(x)$\n",
    "- The variance of the noise $\\epsilon$\n",
    "\n",
    "The expectation here is taken over training sets.\n",
    "\n",
    "Note that $var(\\epsilon)$ is irreducible; thus it is a lower bound on MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bias-Variance Tradeoff\n",
    "---\n",
    "To minimize MSE, then, we want to simultaneously minimize bias and variance.\n",
    "\n",
    "What are these terms?\n",
    "\n",
    "First, **variance** of $\\hat f(x)$ is the variation in $\\hat f(x)$ over different training sets.\n",
    "\n",
    "It is a measure of the stability, in some sense, of the model.  Small changes to the training set should result in only small changes in the approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider a couple of models on our problem above: an order 1 model, and an order 6 model, trained on two different training sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX2, trainY2 = sample(n, f, [-5, 5], 3)\n",
    "Yhat1_1 = phi(X, 1) @ lsq(phi(trainX, 1), trainY)\n",
    "Yhat1_6 = phi(X, 6) @ lsq(phi(trainX, 6), trainY)\n",
    "Yhat2_1 = phi(X, 1) @ lsq(phi(trainX2, 1), trainY2)\n",
    "Yhat2_6 = phi(X, 6) @ lsq(phi(trainX2, 6), trainY2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Plotting the results against each other, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1); plt.plot(trainX, trainY, 'k.', trainX2, trainY2, 'g.', X, Yhat1_1, 'r-', X, Yhat2_1, 'c-')\n",
    "plt.subplot(1,2,2); plt.plot(trainX, trainY, 'k.', trainX2, trainY2, 'g.', X, Yhat1_6, 'r-', X, Yhat2_6, 'c-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of the order 1 model is clearly much smaller than the variance of the order 6 model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Second, **bias** of $\\hat f(x)$ measures the error introduced by the model.\n",
    "\n",
    "Roughly speaking, bias measures the difference between the absolute best fit your model can make and the true $f(x)$.\n",
    "\n",
    "Put another way, if you had unlimited training data, which model would give the best result?\n",
    "\n",
    "In the diagrams above, it is clear that the order 1 (linear) model is too simple; it has a large bias.\n",
    "\n",
    "The order 6 model, on the other hand, clearly has the representational power to reflect the real story; it has small bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The tradeoff, then, is the source of our \"bathtub\" plot.\n",
    "\n",
    "As model complexity increases, we reduce bias, but we increase variance.\n",
    "\n",
    "- Variance is affected by size of training data and noise\n",
    "- Small training data (relative to noise) is the common case\n",
    "\n",
    "Going the other way, we reduce variance, but increase bias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following plot is *very* notional:\n",
    "\n",
    "- Estimating bias via lots of training data (for orders < 3)\n",
    "- Estimating variance via many trials\n",
    "- Variance of $\\epsilon$ known from our experimental setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = np.arange(-5, 5, 0.1)\n",
    "Y = f(X)\n",
    "\n",
    "btX, btY = sample(1000, f, [-5, 5], 3)\n",
    "bias = [0] * 6\n",
    "for i, p in enumerate([1,2]):\n",
    "    btw = lsq(phi(btX, p), btY)\n",
    "    bias[i] = rmse(Y, phi(X, p) @ btw) ** 2\n",
    "\n",
    "n = 20\n",
    "tsets = { 'x': [], 'y': []}\n",
    "for i in range(50):\n",
    "    tX, tY = sample(n, f, [-5, 5], 3)\n",
    "    tsets['x'].append(tX)\n",
    "    tsets['y'].append(tY)\n",
    "\n",
    "variance = [0] * 6\n",
    "orders = range(1,7)\n",
    "for i, p in enumerate(orders):\n",
    "    yhats = []\n",
    "    for j in range(50):\n",
    "        w = lsq(phi(tsets['x'][j], p), tsets['y'][j])\n",
    "        yhats.append(phi(X, p) @ w)\n",
    "    variance[i] = (np.var(np.array(yhats), axis=0)).mean()\n",
    "\n",
    "MSE = np.array(bias) + np.array(variance) + 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(orders, bias, 'r-', orders, variance, 'b-', orders, [9]*6, 'k:', orders, MSE, 'g--')\n",
    "plt.ylim([-5, 85])\n",
    "plt.legend(['Bias', 'Variance', '$\\epsilon$', 'MSE'], loc = 'upper center')\n",
    "plt.xlabel('order')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "livereveal": {
   "height": 768,
   "start_slideshow_at": "selected",
   "theme": "mines",
   "transition": "slide",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
