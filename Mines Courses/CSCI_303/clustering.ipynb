{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 6 : Clustering\n",
    "- Name: Carson Stevens\n",
    "- Date: 11/11/2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Description\n",
    "\n",
    "Practice clustering on a using the well known and very popular `Iris` Dataset! The Iris flower data set is fun for learning supervised classification algorithms, and is known as a difficult case for unsupervised learning. \n",
    "https://cran.r-project.org/web/packages/dendextend/vignettes/Cluster_Analysis.html\n",
    "<br><br>Yes, there are many examples out there, but see if you can do it yourself :). We can easily hypothesize on how many clusters would yield the best result, so let us prove it through a simple experiment that you could repeat with additional data sets.\n",
    "\n",
    "### Grading\n",
    "\n",
    "For grading purposes, we will clear all outputs from all your cells and then run them all from the top.  Please test your notebook in the same fashion before turning it in.\n",
    "\n",
    "### Submitting Your Solution\n",
    "\n",
    "To submit your notebook, first clear all the cells (this won't matter too much this time, but for larger data sets in the future, it will make the file smaller).  Then use the File->Download As->Notebook to obtain the notebook file.  Finally, submit the notebook file on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Data Generation (5 points)\n",
    "Reference for more information: Chapter 5.11 K-Means in the online course book.\n",
    "\n",
    "1. Load the `iris` dataset and separate into `X` and `y` variables (our ground truth labels will just be used for visualization).\n",
    "2. Write a hypothesis on how many clusters will yield the best labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data  \n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hypothesis**(Edit this cell)\n",
    ">\n",
    "> Since there are 3 different families of flowers, the best k should be 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Data exploration (10 points)\n",
    "\n",
    "This is the step where you would normally conduct any needed preprocessing, data wrangling, and investigation of the data.\n",
    "<br>**Note:** `print(iris.DESCR)` prints the iris dataset description, provided you loaded it into a variable named `iris`\n",
    "\n",
    "a. Using your skills from previous projects, provide code below to produce answers to the following questions (edit this cell with your answers): \n",
    "\n",
    "    1. How many features are provided?\n",
    "        \n",
    "        There are 4 features: \n",
    "        - sepal length in cm\n",
    "        - sepal width in cm\n",
    "        - petal length in cm\n",
    "        - petal width in cm\n",
    "        \n",
    "    2. How many total observations?\n",
    "\n",
    "        150 (50 in each of three classes)\n",
    "\n",
    "    3. How many different labels are included, what are they called, and is it a balanced dataset with the same number of observations for each class?\n",
    "    \n",
    "        There are 3 labels (50 in each of three classes: Balanced):\n",
    "        - Iris-Setosa\n",
    "        - Iris-Versicolour\n",
    "        - Iris-Virginica\n",
    "        \n",
    "b. Create a 2D or 3D scatter plot of two or three of the features and use the y labels for color coding. Do not reduce the data or number of features in any way (you will do this by applying PCA in problem 5).\n",
    "\n",
    "c. Since clusters can be influenced by the magnitudes of the variables, normalize the feature data and plot a histogram of the normalized features data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a\n",
    "#print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap = ListedColormap(['r', 'y','b'])\n",
    "plt.scatter(x[:,0], x[:, 1], c=y, cmap=cmap)\n",
    "plt.title(\"Clustering using Sepal Length & Width\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c. Normalization\n",
    "normalized = Normalizer()\n",
    "normalized.fit(x)\n",
    "xNorm = normalized.transform(x)\n",
    "plt.hist(xNorm)\n",
    "plt.title(\"Normalized Iris Histogram\")\n",
    "plt.ylabel(\"Number of flower\")\n",
    "plt.xlabel(\"Length/Width in cm\")\n",
    "plt.legend([\"sepal length\", \"sepal width\", \"petal length\", \"petal width\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Unsupervised Learning - Clustering (15 points)\n",
    "Conduct clustering experiments with one of algorithms discussed in class (e.g., k-means) for number of clusters k = 2-10. Create another 2D or 3D scatter plot utilizing the <b>cluster assignments</b> for color coding (this output can be a plot for each of the values of k or just one final plot using the value of k from your best Silhouette result obtained in Problem 4 below).  \n",
    "\n",
    "#### Steps:\n",
    "Repeat for each value of k (maybe a loop here would be appropriate):\n",
    "1. Create model object\n",
    "2. Train or fit the model\n",
    "3. Predict cluster assignments\n",
    "4. Calculate Silhouette width (see Problem 4)\n",
    "4. Plot points color coded by class labels predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    " \n",
    "bestSilhouette = 0\n",
    "bestCluster = 0\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++')\n",
    "    y = kmeans.fit_predict(xNorm)\n",
    "    silhouette= silhouette_score(xNorm, y)\n",
    "    if(silhouette > bestSilhouette):\n",
    "        bestSilhouette = silhouette\n",
    "        bestCluster = i\n",
    "    plt.scatter(xNorm[:,0], xNorm[:,1], c=y, cmap=plt.cm.get_cmap('Accent'))\n",
    "    #plt.legend([\"Setosa\", \"Versicolor\", \"Virginica\"])\n",
    "    plt.title(\"Clustering with %i Clusters\" % i)\n",
    "    plt.show()  \n",
    "print(\"The best cluster value is:\\t\", bestCluster)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Evaluate results (20 points)\n",
    "\n",
    "As we have discussed, validating an usupervised problem is difficult. There is a metric that can be used to determine the density or separation of cluster assignments, called Silhouette width. In this step, perform analysis of results using the above `k = 2-10` and compute the Silhouette width (Hint: possibly you can just add code to your loop in problem 3 and store the results in a list of values). \n",
    "\n",
    "Scikit Learn has a great example for Silhouette analysis [here](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html)\n",
    "\n",
    "1. For each k (k = 2-10), what are the Silhouette width values?\n",
    " \n",
    "\n",
    "2. Discuss if your best number of clusters (highest Silhouette width value) matches your hypothesis from Problem 1.\n",
    "\n",
    "\n",
    "The best result was obtained with k=2. This didn't fit my hypothesis of 3. I thought since there was 3 types of flowers, that the best cluster result would be 3, yet the result of k=2: 0.8188570772941627 is much better than k=3: 0.5761482778685276."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestSilhouette = 0\n",
    "bestCluster = 0\n",
    "cluster = 0\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++')\n",
    "    y = kmeans.fit_predict(xNorm)\n",
    "    silhouette= silhouette_score(xNorm, y)\n",
    "    cluster = i +1 #for 0 indexing\n",
    "    print(\"Silhouette Score with %i Clusters:\\t\" %i, silhouette,)\n",
    "    if(silhouette > bestSilhouette):\n",
    "        bestSilhouette = silhouette\n",
    "        bestCluster = i\n",
    "    \n",
    "print(\"\\nThe best cluster value is:\\t\", bestCluster)\n",
    "print(\"The silhouette score was:\\t\", bestSilhouette)\n",
    "#discussion above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 (15 points): Principal Component Analysis (PCA)\n",
    "PCA is the most popular form of dimensionality reduction, which basically, rotates and transforms the data into a new subspace, such that the resultant matrix has:\n",
    "- Most relevance (variation) now associated with first feature\n",
    "- Second feature gets the next most, etc.\n",
    "#### Steps:\n",
    "1. Reduce the feature data (X) using PCA\n",
    "2. Repeat the same experiment from problem 3 above (remember your plots are now the 1st, 2nd, and possibly 3rd principal component vs. the raw feature data like before).\n",
    "3. Compare and contrast results to those from previous/non-PCA problems; does it perform better/worse/same? Provide discussion below (this could vary, depending on setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering with PCA\n",
    "bestSilhouette = -2\n",
    "bestCluster = 0\n",
    "bestComponent= 0\n",
    "for i in range(2, 11):\n",
    "    for j in range(1, 5):\n",
    "        Xpca = PCA(n_components=j).fit_transform(xNorm)\n",
    "        kmeans = KMeans(n_clusters = i, init = 'k-means++')\n",
    "        y = kmeans.fit_predict(Xpca)\n",
    "        silhouette= silhouette_score(Xpca, y)\n",
    "        if(silhouette > bestSilhouette):\n",
    "            bestComponent = j\n",
    "            bestSilhouette = silhouette\n",
    "            bestCluster = i\n",
    "        plt.scatter(xNorm[:,0], xNorm[:,1], c=y, cmap=plt.cm.get_cmap('Accent'))\n",
    "        #plt.legend([\"Setosa\", \"Versicolor\", \"Virginica\"])\n",
    "        plt.title(\"PCA with %i Components & %i Clusters\" %(j, i))\n",
    "        plt.show()\n",
    "print(\"The best PCA has\", bestComponent, \"component(s)\")\n",
    "print(\"With a cluster value of:\\t\", bestCluster)\n",
    "print(\"The silhouette score was:\\t\", bestSilhouette)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss new results**(Edit this cell)\n",
    ">\n",
    "> The Kmeans algorithm w/ PCA provided a better silhouette score for my runs: (0.818857077294163 VS w/PCA: 0.8793430588300643). The best results were obtained from the algorithm when k = 2 with 1 component. This did not match my hypothesis (like stated in 4). The test (w/ PCA) that preformed the best used the same number of clusters (k=2) as in 3 & 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Finished! Treat yourself by taking this questionnaire\n",
    "### Questionnaire\n",
    "1) How long did you spend on this assignment?\n",
    "<br>\n",
    "    1.5 hours\n",
    "<br>\n",
    "2) What did you like about it? What did you not like about it?\n",
    "<br>\n",
    "    It was interesting to see how the different number of clusters/dimensions produced a wide range of results\n",
    "<br>\n",
    "3) Did you find any errors or is there anything you would like changed?\n",
    "<br>\n",
    "    No changes needed\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
