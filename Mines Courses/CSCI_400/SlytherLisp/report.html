<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title>Test Report</title>
    <link href="assets/style.css" rel="stylesheet" type="text/css"/></head>
  <body onLoad="init()">
    <script>/* This Source Code Form is subject to the terms of the Mozilla Public
 * License, v. 2.0. If a copy of the MPL was not distributed with this file,
 * You can obtain one at http://mozilla.org/MPL/2.0/. */


function toArray(iter) {
    if (iter === null) {
        return null;
    }
    return Array.prototype.slice.call(iter);
}

function find(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return elem.querySelector(selector);
}

function find_all(selector, elem) {
    if (!elem) {
        elem = document;
    }
    return toArray(elem.querySelectorAll(selector));
}

function sort_column(elem) {
    toggle_sort_states(elem);
    var colIndex = toArray(elem.parentNode.childNodes).indexOf(elem);
    var key;
    if (elem.classList.contains('numeric')) {
        key = key_num;
    } else if (elem.classList.contains('result')) {
        key = key_result;
    } else {
        key = key_alpha;
    }
    sort_table(elem, key(colIndex));
}

function show_all_extras() {
    find_all('.col-result').forEach(show_extras);
}

function hide_all_extras() {
    find_all('.col-result').forEach(hide_extras);
}

function show_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.remove("collapsed");
    expandcollapse.classList.remove("expander");
    expandcollapse.classList.add("collapser");
}

function hide_extras(colresult_elem) {
    var extras = colresult_elem.parentNode.nextElementSibling;
    var expandcollapse = colresult_elem.firstElementChild;
    extras.classList.add("collapsed");
    expandcollapse.classList.remove("collapser");
    expandcollapse.classList.add("expander");
}

function show_filters() {
    var filter_items = document.getElementsByClassName('filter');
    for (var i = 0; i < filter_items.length; i++)
        filter_items[i].hidden = false;
}

function add_collapse() {
    // Add links for show/hide all
    var resulttable = find('table#results-table');
    var showhideall = document.createElement("p");
    showhideall.innerHTML = '<a href="javascript:show_all_extras()">Show all details</a> / ' +
                            '<a href="javascript:hide_all_extras()">Hide all details</a>';
    resulttable.parentElement.insertBefore(showhideall, resulttable);

    // Add show/hide link to each result
    find_all('.col-result').forEach(function(elem) {
        var collapsed = get_query_parameter('collapsed') || 'Passed';
        var extras = elem.parentNode.nextElementSibling;
        var expandcollapse = document.createElement("span");
        if (collapsed.includes(elem.innerHTML)) {
            extras.classList.add("collapsed");
            expandcollapse.classList.add("expander");
        } else {
            expandcollapse.classList.add("collapser");
        }
        elem.appendChild(expandcollapse);

        elem.addEventListener("click", function(event) {
            if (event.currentTarget.parentNode.nextElementSibling.classList.contains("collapsed")) {
                show_extras(event.currentTarget);
            } else {
                hide_extras(event.currentTarget);
            }
        });
    })
}

function get_query_parameter(name) {
    var match = RegExp('[?&]' + name + '=([^&]*)').exec(window.location.search);
    return match && decodeURIComponent(match[1].replace(/\+/g, ' '));
}

function init () {
    reset_sort_headers();

    add_collapse();

    show_filters();

    toggle_sort_states(find('.initial-sort'));

    find_all('.sortable').forEach(function(elem) {
        elem.addEventListener("click",
                              function(event) {
                                  sort_column(elem);
                              }, false)
    });

};

function sort_table(clicked, key_func) {
    var rows = find_all('.results-table-row');
    var reversed = !clicked.classList.contains('asc');
    var sorted_rows = sort(rows, key_func, reversed);
    /* Whole table is removed here because browsers acts much slower
     * when appending existing elements.
     */
    var thead = document.getElementById("results-table-head");
    document.getElementById('results-table').remove();
    var parent = document.createElement("table");
    parent.id = "results-table";
    parent.appendChild(thead);
    sorted_rows.forEach(function(elem) {
        parent.appendChild(elem);
    });
    document.getElementsByTagName("BODY")[0].appendChild(parent);
}

function sort(items, key_func, reversed) {
    var sort_array = items.map(function(item, i) {
        return [key_func(item), i];
    });
    var multiplier = reversed ? -1 : 1;

    sort_array.sort(function(a, b) {
        var key_a = a[0];
        var key_b = b[0];
        return multiplier * (key_a >= key_b ? 1 : -1);
    });

    return sort_array.map(function(item) {
        var index = item[1];
        return items[index];
    });
}

function key_alpha(col_index) {
    return function(elem) {
        return elem.childNodes[1].childNodes[col_index].firstChild.data.toLowerCase();
    };
}

function key_num(col_index) {
    return function(elem) {
        return parseFloat(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function key_result(col_index) {
    return function(elem) {
        var strings = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed',
                       'Skipped', 'Passed'];
        return strings.indexOf(elem.childNodes[1].childNodes[col_index].firstChild.data);
    };
}

function reset_sort_headers() {
    find_all('.sort-icon').forEach(function(elem) {
        elem.parentNode.removeChild(elem);
    });
    find_all('.sortable').forEach(function(elem) {
        var icon = document.createElement("div");
        icon.className = "sort-icon";
        icon.textContent = "vvv";
        elem.insertBefore(icon, elem.firstChild);
        elem.classList.remove("desc", "active");
        elem.classList.add("asc", "inactive");
    });
}

function toggle_sort_states(elem) {
    //if active, toggle between asc and desc
    if (elem.classList.contains('active')) {
        elem.classList.toggle('asc');
        elem.classList.toggle('desc');
    }

    //if inactive, reset all other functions and add ascending active
    if (elem.classList.contains('inactive')) {
        reset_sort_headers();
        elem.classList.remove('inactive');
        elem.classList.add('active');
    }
}

function is_all_rows_hidden(value) {
  return value.hidden == false;
}

function filter_table(elem) {
    var outcome_att = "data-test-result";
    var outcome = elem.getAttribute(outcome_att);
    class_outcome = outcome + " results-table-row";
    var outcome_rows = document.getElementsByClassName(class_outcome);

    for(var i = 0; i < outcome_rows.length; i++){
        outcome_rows[i].hidden = !elem.checked;
    }

    var rows = find_all('.results-table-row').filter(is_all_rows_hidden);
    var all_rows_hidden = rows.length == 0 ? true : false;
    var not_found_message = document.getElementById("not-found-message");
    not_found_message.hidden = !all_rows_hidden;
}
</script>
    <h1>report.html</h1>
    <p>Report generated on 31-Mar-2019 at 18:47:19 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a> v1.20.0</p>
    <h2>Environment</h2>
    <table id="environment">
      <tr>
        <td>Packages</td>
        <td>{&apos;pytest&apos;: &apos;3.8.0&apos;, &apos;py&apos;: &apos;1.6.0&apos;, &apos;pluggy&apos;: &apos;0.7.1&apos;}</td></tr>
      <tr>
        <td>Platform</td>
        <td>Windows-10-10.0.17134-SP0</td></tr>
      <tr>
        <td>Plugins</td>
        <td>{&apos;hypothesis&apos;: &apos;4.6.1&apos;, &apos;remotedata&apos;: &apos;0.3.0&apos;, &apos;openfiles&apos;: &apos;0.3.0&apos;, &apos;metadata&apos;: &apos;1.8.0&apos;, &apos;html&apos;: &apos;1.20.0&apos;, &apos;doctestplus&apos;: &apos;0.1.3&apos;, &apos;arraydiff&apos;: &apos;0.2&apos;}</td></tr>
      <tr>
        <td>Python</td>
        <td>3.7.0</td></tr></table>
    <h2>Summary</h2>
    <p>23 tests ran in 2.16 seconds. </p>
    <p class="filter" hidden="true">(Un)check the boxes to filter the results.</p><input checked="true" class="filter" data-test-result="passed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="passed">0 passed</span>, <input checked="true" class="filter" data-test-result="skipped" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="skipped">0 skipped</span>, <input checked="true" class="filter" data-test-result="failed" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="failed">23 failed</span>, <input checked="true" class="filter" data-test-result="error" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="error">0 errors</span>, <input checked="true" class="filter" data-test-result="xfailed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xfailed">0 expected failures</span>, <input checked="true" class="filter" data-test-result="xpassed" disabled="true" hidden="true" name="filter_checkbox" onChange="filter_table(this)" type="checkbox"/><span class="xpassed">0 unexpected passes</span>
    <h2>Results</h2>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable result initial-sort" col="result">Result</th>
          <th class="sortable" col="name">Test</th>
          <th class="sortable numeric" col="duration">Duration</th>
          <th>Links</th></tr>
        <tr hidden="true" id="not-found-message">
          <th colspan="4">No results found. Try to check the filters</th></tr></thead>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test__docstring_slyther.parser.lex.txt::test__docstring_slyther.parser.lex.txt</td>
          <td class="col-duration">0.01</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">006 <br/>007 This is a *generator function* that splits a piece of code into<br/>008 lexical tokens, emitting whole tokens each time one is encountered.<br/>009 <br/>010 A lexical token is not just a string: this function should assign a<br/>011 type to each piece of data as appropriate.<br/>012 <br/>013 For a high level overview, consider this invocation:<br/>014 <br/>015 &gt;&gt;&gt; toks = list(lex(&quot;(define (do-123 fun) \n (map fun &#x27;(1 2 3.0))) \n&quot;))<br/>UNEXPECTED EXCEPTION: NotImplementedError(&#x27;Deliverable 2&#x27;)<br/>Traceback (most recent call last):<br/><br/>  File &quot;C:\Users\steve\Anaconda3\lib\doctest.py&quot;, line 1329, in __run<br/>    compileflags, 1), test.globs)<br/><br/>  File &quot;&lt;doctest test__docstring_slyther.parser.lex.txt[1]&gt;&quot;, line 1, in &lt;module&gt;<br/><br/>  File &quot;c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py&quot;, line 211, in lex<br/>    raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><br/>NotImplementedError: Deliverable 2<br/><br/>C:\Users\steve\OneDrive\Desktop\Mines-Courses\Mines Courses\CSCI_400\SlytherLisp\tests\d2\test__docstring_slyther.parser.lex.txt:15: UnexpectedException<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test__docstring_slyther.parser.parse.txt::test__docstring_slyther.parser.parse.txt</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">009 &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>010 &gt;&gt;&gt; lp = LParen()<br/>011 &gt;&gt;&gt; rp = RParen()<br/>012 &gt;&gt;&gt; q = Quote()<br/>013 <br/>014 Here is a simple example:<br/>015 <br/>016 &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>017 ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>018 &gt;&gt;&gt; parser = parse(iter(tokens))<br/>UNEXPECTED EXCEPTION: NotImplementedError(&#x27;Deliverable 2&#x27;)<br/>Traceback (most recent call last):<br/><br/>  File &quot;C:\Users\steve\Anaconda3\lib\doctest.py&quot;, line 1329, in __run<br/>    compileflags, 1), test.globs)<br/><br/>  File &quot;&lt;doctest test__docstring_slyther.parser.parse.txt[6]&gt;&quot;, line 1, in &lt;module&gt;<br/><br/>  File &quot;c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py&quot;, line 398, in parse<br/>    raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><br/>NotImplementedError: Deliverable 2<br/><br/>C:\Users\steve\OneDrive\Desktop\Mines-Courses\Mines Courses\CSCI_400\SlytherLisp\tests\d2\test__docstring_slyther.parser.parse.txt:18: UnexpectedException<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test__docstring_slyther.parser.parse_strlit.txt::test__docstring_slyther.parser.parse_strlit.txt</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">030 | ``\&quot;``          | ASCII Value 34     |<br/>031 +-----------------+--------------------+<br/>032 | ``\\``          | ASCII Value 92     |<br/>033 +-----------------+--------------------+<br/>034 | ``\x##``        | Hex value ``##``   |<br/>035 +-----------------+--------------------+<br/>036 | ``\0##``        | Octal value ``##`` |<br/>037 +-----------------+--------------------+<br/>038 <br/>039 &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>UNEXPECTED EXCEPTION: NotImplementedError(&#x27;Deliverable 2&#x27;)<br/>Traceback (most recent call last):<br/><br/>  File &quot;C:\Users\steve\Anaconda3\lib\doctest.py&quot;, line 1329, in __run<br/>    compileflags, 1), test.globs)<br/><br/>  File &quot;&lt;doctest test__docstring_slyther.parser.parse_strlit.txt[1]&gt;&quot;, line 1, in &lt;module&gt;<br/><br/>  File &quot;c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py&quot;, line 279, in parse_strlit<br/>    raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><br/>NotImplementedError: Deliverable 2<br/><br/>C:\Users\steve\OneDrive\Desktop\Mines-Courses\Mines Courses\CSCI_400\SlytherLisp\tests\d2\test__docstring_slyther.parser.parse_strlit.txt:39: UnexpectedException<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test__docstring_slyther.parser.txt::test__docstring_slyther.parser.txt</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">001 &gt;&gt;&gt; from slyther.parser import *<br/>002 <br/>003 This module defines parsing utilities in SlytherLisp.<br/>004 <br/>005 &gt;&gt;&gt; parser = parse(lex(&#x27;(print &quot;Hello, World!&quot;)&#x27;))<br/>UNEXPECTED EXCEPTION: NotImplementedError(&#x27;Deliverable 2&#x27;)<br/>Traceback (most recent call last):<br/><br/>  File &quot;C:\Users\steve\Anaconda3\lib\doctest.py&quot;, line 1329, in __run<br/>    compileflags, 1), test.globs)<br/><br/>  File &quot;&lt;doctest test__docstring_slyther.parser.txt[1]&gt;&quot;, line 1, in &lt;module&gt;<br/><br/>  File &quot;c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py&quot;, line 211, in lex<br/>    raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><br/>NotImplementedError: Deliverable 2<br/><br/>C:\Users\steve\OneDrive\Desktop\Mines-Courses\Mines Courses\CSCI_400\SlytherLisp\tests\d2\test__docstring_slyther.parser.txt:5: UnexpectedException<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_lexer.py::test_fp_parse</td>
          <td class="col-duration">1.07</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(from_regex(r&#x27;\s*-?([0-9]*\.[0-9]+|[0-9]+\.[0-9]*)\s*&#x27;, fullmatch=True))<br/>&gt;   def test_fp_parse(s):<br/><br/>tests\d2\test_lexer.py:9: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_lexer.py:10: in test_fp_parse<br/>    num = next(lex(s))<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>code = &#x27;.0&#x27;<br/><br/>    def lex(code):<br/>        r&quot;&quot;&quot;<br/>        IMPORTANT: read this entire docstring before implementing this function!<br/>        Please ask for help on Piazza or come to office hours if you don&#x27;t<br/>        understand something in here.<br/>    <br/>        This is a *generator function* that splits a piece of code into<br/>        lexical tokens, emitting whole tokens each time one is encountered.<br/>    <br/>        A lexical token is not just a string: this function should assign a<br/>        type to each piece of data as appropriate.<br/>    <br/>        For a high level overview, consider this invocation:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(&quot;(define (do-123 fun) \n (map fun &#x27;(1 2 3.0))) \n&quot;))<br/>        &gt;&gt;&gt; toks    # doctest: +NORMALIZE_WHITESPACE<br/>        [LParen, define, LParen, do-123, fun, RParen,<br/>            LParen, map, fun, Quote, LParen, 1, 2, 3.0, RParen, RParen, RParen]<br/>    <br/>        Let&#x27;s look at the types of each piece of data here. The ``LParen``,<br/>        ``RParen``, and ``Quote`` bits are *instances of* the subclasses of<br/>        the ``ControlToken`` class above. ``1`` and ``2`` are Python integers,<br/>        and ``3.0`` is a Python ``float``. Finally, everything else here is a<br/>        ``Symbol``.<br/>    <br/>        &gt;&gt;&gt; print(*(t.__class__.__name__ for t in toks))<br/>        ...                                 # doctest: +NORMALIZE_WHITESPACE<br/>        LParen Symbol LParen Symbol Symbol RParen<br/>        LParen Symbol Symbol Quote LParen int int float RParen RParen RParen<br/>    <br/>        So what goes into this process? First, we need a pretty good definition<br/>        of each of the tokens in the language. The lexer will emit what matches<br/>        the following:<br/>    <br/>        :Control Tokens:<br/>            Left parenthesis, right parenthesis, and single quotes.<br/>        :String Literals:<br/>            A double quote (``&quot;``) followed by any (including zero) amount of<br/>            characters which are not a double quote. The double quote<br/>            character ends a string, *unless* a backslash precedes it. These<br/>            string literals should be parsed by the ``parse_strlit`` function<br/>            before they are emitted by the lexer.<br/>        :Integer Literals:<br/>            An optional negative sign, followed by 1 or more digits. There cannot<br/>            be a period following the digits, as it should be parsed as a floating<br/>            point number (see below). This should be emitted as Python&#x27;s ``int``<br/>            type.<br/>        :Floating Point Literals:<br/>            An optional negative sign, followed by zero or more digits, followed<br/>            by a period (decimal point), followed by zero or more digits. All<br/>            floating point numbers must have at least one digit. These should be<br/>            emitted as Python&#x27;s ``float`` type.<br/>        :Symbols:<br/>            These are a collection of 1 or more of **any characters**, not<br/>            including single/double quotes, parenthesis, semicolons, or<br/>            whitespace. In addition, symbols cannot start with digits or<br/>            periods.<br/>    <br/>        The following are ignored, and not omitted by the lexer:<br/>    <br/>        :Whitespace:<br/>            Groups of whitespace characters in-between tokens.<br/>        :Comments:<br/>            A semicolon, followed by any amount of characters until the end<br/>            of a line.<br/>        :Shebang Lines:<br/>            A line at the top of the file which starts with ``#!``. For example::<br/>    <br/>                #!/usr/bin/env slyther<br/>    <br/>            Note that it only a shebang line if it&#x27;s at the top of the file.<br/>            Elsewhere, this would look like two symbols.<br/>    <br/>        Anything which does not match above should raise a ``SyntaxError``. Think<br/>        for a second: what might not match the above?<br/>    <br/>        That&#x27;s the end of the technical specification... what follows is examples<br/>        which reading may give you an idea on what to do here.<br/>    <br/>        Strings should be parsed using ``parse_strlit``:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(r&#x27;(print &quot;hello \&quot;world\&quot;!&quot;)&#x27;))<br/>        &gt;&gt;&gt; toks<br/>        [LParen, print, &quot;hello \&quot;world\&quot;!&quot;, RParen]<br/>        &gt;&gt;&gt; type(toks[1])<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>        &gt;&gt;&gt; type(toks[2])<br/>        &lt;class &#x27;slyther.types.String&#x27;&gt;<br/>    <br/>        Symbols are defined based on what characters cannot be in them, not which<br/>        can. This means you can have symbols like this:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;lambda-is-λ ¯\_[ツ]_/¯&#x27;))<br/>        [lambda-is-λ, ¯\_[ツ]_/¯]<br/>    <br/>        Since symbols cannot start with a digit, this function should separate the<br/>        numerical literal from the symbol when things like this happen:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print 8-dogcows)&#x27;))<br/>        [LParen, print, 8, -dogcows, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;(print -8.0-dogcows)&#x27;))<br/>        [LParen, print, -8.0, -dogcows, RParen]<br/>    <br/>        And since symbols can have digits and dots in the middle, make sure these<br/>        are parsed properly:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print dogcows-8.0)&#x27;))<br/>        [LParen, print, dogcows-8.0, RParen]<br/>    <br/>        Quotes can&#x27;t occur in the middle of symbols and numbers, so these quotes<br/>        separate the tokens below, even without whitespace:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(print&#x27;hello-world&#x27;4&#x27;8.0)&quot;))<br/>        [LParen, print, Quote, hello-world, Quote, 4, Quote, 8.0, RParen]<br/>    <br/>        Shebang lines **only at the front of the string, before any whitespace**<br/>        should be ignored, and not emitted as a token:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;#!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;#!slyther\n(print 1)&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot; #!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [#!/usr/bin/env, slyther, LParen, print, 1, RParen]<br/>    <br/>        Comments start at a semicolon and go until the end of line (or,<br/>        potentially the end of the input string). Note that string literals<br/>        might contain semicolons: these don&#x27;t start a comment, beware.<br/>        Comments should not be emitted from the lexer.<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(here-comes; a comment!\n &quot;no comment ; here&quot;;comment()\n)&#x27;))<br/>        [LParen, here-comes, &quot;no comment ; here&quot;, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;; commments can contain ; inside them\n&#x27;))<br/>        []<br/>    <br/>        When an error is encountered, ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;(print &quot;Hello, World!\&quot;)&#x27;))        # unclosed string<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>        &gt;&gt;&gt; list(lex(r&#x27;.symbol&#x27;))        # symbols cannot start with period<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>    <br/>        Don&#x27;t worry about handling unmatched parenthesis or single quotes in an<br/>        invalid position. This will be the parser&#x27;s job! In other words, the<br/>        lexer should be no smarter than it needs to be to do its job.<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(((&quot;))<br/>        [LParen, LParen, LParen]<br/>        &gt;&gt;&gt; list(lex(&quot;(&#x27;)&quot;))<br/>        [LParen, Quote, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;&#x27;&quot;))<br/>        [Quote]<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:211: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_fp_parse(s=&#x27;.0&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_lexer.py::test_unclosed_string</td>
          <td class="col-duration">0.03</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(from_regex(r&#x27;\s*&quot;(\\&quot;|[^&quot;])*&#x27;, fullmatch=True))<br/>&gt;   def test_unclosed_string(s):<br/><br/>tests\d2\test_lexer.py:15: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_lexer.py:17: in test_unclosed_string<br/>    next(lex(s))<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>code = &#x27;&quot;&#x27;<br/><br/>    def lex(code):<br/>        r&quot;&quot;&quot;<br/>        IMPORTANT: read this entire docstring before implementing this function!<br/>        Please ask for help on Piazza or come to office hours if you don&#x27;t<br/>        understand something in here.<br/>    <br/>        This is a *generator function* that splits a piece of code into<br/>        lexical tokens, emitting whole tokens each time one is encountered.<br/>    <br/>        A lexical token is not just a string: this function should assign a<br/>        type to each piece of data as appropriate.<br/>    <br/>        For a high level overview, consider this invocation:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(&quot;(define (do-123 fun) \n (map fun &#x27;(1 2 3.0))) \n&quot;))<br/>        &gt;&gt;&gt; toks    # doctest: +NORMALIZE_WHITESPACE<br/>        [LParen, define, LParen, do-123, fun, RParen,<br/>            LParen, map, fun, Quote, LParen, 1, 2, 3.0, RParen, RParen, RParen]<br/>    <br/>        Let&#x27;s look at the types of each piece of data here. The ``LParen``,<br/>        ``RParen``, and ``Quote`` bits are *instances of* the subclasses of<br/>        the ``ControlToken`` class above. ``1`` and ``2`` are Python integers,<br/>        and ``3.0`` is a Python ``float``. Finally, everything else here is a<br/>        ``Symbol``.<br/>    <br/>        &gt;&gt;&gt; print(*(t.__class__.__name__ for t in toks))<br/>        ...                                 # doctest: +NORMALIZE_WHITESPACE<br/>        LParen Symbol LParen Symbol Symbol RParen<br/>        LParen Symbol Symbol Quote LParen int int float RParen RParen RParen<br/>    <br/>        So what goes into this process? First, we need a pretty good definition<br/>        of each of the tokens in the language. The lexer will emit what matches<br/>        the following:<br/>    <br/>        :Control Tokens:<br/>            Left parenthesis, right parenthesis, and single quotes.<br/>        :String Literals:<br/>            A double quote (``&quot;``) followed by any (including zero) amount of<br/>            characters which are not a double quote. The double quote<br/>            character ends a string, *unless* a backslash precedes it. These<br/>            string literals should be parsed by the ``parse_strlit`` function<br/>            before they are emitted by the lexer.<br/>        :Integer Literals:<br/>            An optional negative sign, followed by 1 or more digits. There cannot<br/>            be a period following the digits, as it should be parsed as a floating<br/>            point number (see below). This should be emitted as Python&#x27;s ``int``<br/>            type.<br/>        :Floating Point Literals:<br/>            An optional negative sign, followed by zero or more digits, followed<br/>            by a period (decimal point), followed by zero or more digits. All<br/>            floating point numbers must have at least one digit. These should be<br/>            emitted as Python&#x27;s ``float`` type.<br/>        :Symbols:<br/>            These are a collection of 1 or more of **any characters**, not<br/>            including single/double quotes, parenthesis, semicolons, or<br/>            whitespace. In addition, symbols cannot start with digits or<br/>            periods.<br/>    <br/>        The following are ignored, and not omitted by the lexer:<br/>    <br/>        :Whitespace:<br/>            Groups of whitespace characters in-between tokens.<br/>        :Comments:<br/>            A semicolon, followed by any amount of characters until the end<br/>            of a line.<br/>        :Shebang Lines:<br/>            A line at the top of the file which starts with ``#!``. For example::<br/>    <br/>                #!/usr/bin/env slyther<br/>    <br/>            Note that it only a shebang line if it&#x27;s at the top of the file.<br/>            Elsewhere, this would look like two symbols.<br/>    <br/>        Anything which does not match above should raise a ``SyntaxError``. Think<br/>        for a second: what might not match the above?<br/>    <br/>        That&#x27;s the end of the technical specification... what follows is examples<br/>        which reading may give you an idea on what to do here.<br/>    <br/>        Strings should be parsed using ``parse_strlit``:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(r&#x27;(print &quot;hello \&quot;world\&quot;!&quot;)&#x27;))<br/>        &gt;&gt;&gt; toks<br/>        [LParen, print, &quot;hello \&quot;world\&quot;!&quot;, RParen]<br/>        &gt;&gt;&gt; type(toks[1])<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>        &gt;&gt;&gt; type(toks[2])<br/>        &lt;class &#x27;slyther.types.String&#x27;&gt;<br/>    <br/>        Symbols are defined based on what characters cannot be in them, not which<br/>        can. This means you can have symbols like this:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;lambda-is-λ ¯\_[ツ]_/¯&#x27;))<br/>        [lambda-is-λ, ¯\_[ツ]_/¯]<br/>    <br/>        Since symbols cannot start with a digit, this function should separate the<br/>        numerical literal from the symbol when things like this happen:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print 8-dogcows)&#x27;))<br/>        [LParen, print, 8, -dogcows, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;(print -8.0-dogcows)&#x27;))<br/>        [LParen, print, -8.0, -dogcows, RParen]<br/>    <br/>        And since symbols can have digits and dots in the middle, make sure these<br/>        are parsed properly:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print dogcows-8.0)&#x27;))<br/>        [LParen, print, dogcows-8.0, RParen]<br/>    <br/>        Quotes can&#x27;t occur in the middle of symbols and numbers, so these quotes<br/>        separate the tokens below, even without whitespace:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(print&#x27;hello-world&#x27;4&#x27;8.0)&quot;))<br/>        [LParen, print, Quote, hello-world, Quote, 4, Quote, 8.0, RParen]<br/>    <br/>        Shebang lines **only at the front of the string, before any whitespace**<br/>        should be ignored, and not emitted as a token:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;#!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;#!slyther\n(print 1)&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot; #!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [#!/usr/bin/env, slyther, LParen, print, 1, RParen]<br/>    <br/>        Comments start at a semicolon and go until the end of line (or,<br/>        potentially the end of the input string). Note that string literals<br/>        might contain semicolons: these don&#x27;t start a comment, beware.<br/>        Comments should not be emitted from the lexer.<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(here-comes; a comment!\n &quot;no comment ; here&quot;;comment()\n)&#x27;))<br/>        [LParen, here-comes, &quot;no comment ; here&quot;, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;; commments can contain ; inside them\n&#x27;))<br/>        []<br/>    <br/>        When an error is encountered, ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;(print &quot;Hello, World!\&quot;)&#x27;))        # unclosed string<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>        &gt;&gt;&gt; list(lex(r&#x27;.symbol&#x27;))        # symbols cannot start with period<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>    <br/>        Don&#x27;t worry about handling unmatched parenthesis or single quotes in an<br/>        invalid position. This will be the parser&#x27;s job! In other words, the<br/>        lexer should be no smarter than it needs to be to do its job.<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(((&quot;))<br/>        [LParen, LParen, LParen]<br/>        &gt;&gt;&gt; list(lex(&quot;(&#x27;)&quot;))<br/>        [LParen, Quote, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;&#x27;&quot;))<br/>        [Quote]<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:211: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_unclosed_string(s=&#x27;&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_lexer.py::test_invalid_period</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(from_regex(r&#x27;\s*\.[^\d]*&#x27;, fullmatch=True))<br/>&gt;   def test_invalid_period(s):<br/><br/>tests\d2\test_lexer.py:21: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_lexer.py:23: in test_invalid_period<br/>    next(lex(s))<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>code = &#x27;.&#x27;<br/><br/>    def lex(code):<br/>        r&quot;&quot;&quot;<br/>        IMPORTANT: read this entire docstring before implementing this function!<br/>        Please ask for help on Piazza or come to office hours if you don&#x27;t<br/>        understand something in here.<br/>    <br/>        This is a *generator function* that splits a piece of code into<br/>        lexical tokens, emitting whole tokens each time one is encountered.<br/>    <br/>        A lexical token is not just a string: this function should assign a<br/>        type to each piece of data as appropriate.<br/>    <br/>        For a high level overview, consider this invocation:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(&quot;(define (do-123 fun) \n (map fun &#x27;(1 2 3.0))) \n&quot;))<br/>        &gt;&gt;&gt; toks    # doctest: +NORMALIZE_WHITESPACE<br/>        [LParen, define, LParen, do-123, fun, RParen,<br/>            LParen, map, fun, Quote, LParen, 1, 2, 3.0, RParen, RParen, RParen]<br/>    <br/>        Let&#x27;s look at the types of each piece of data here. The ``LParen``,<br/>        ``RParen``, and ``Quote`` bits are *instances of* the subclasses of<br/>        the ``ControlToken`` class above. ``1`` and ``2`` are Python integers,<br/>        and ``3.0`` is a Python ``float``. Finally, everything else here is a<br/>        ``Symbol``.<br/>    <br/>        &gt;&gt;&gt; print(*(t.__class__.__name__ for t in toks))<br/>        ...                                 # doctest: +NORMALIZE_WHITESPACE<br/>        LParen Symbol LParen Symbol Symbol RParen<br/>        LParen Symbol Symbol Quote LParen int int float RParen RParen RParen<br/>    <br/>        So what goes into this process? First, we need a pretty good definition<br/>        of each of the tokens in the language. The lexer will emit what matches<br/>        the following:<br/>    <br/>        :Control Tokens:<br/>            Left parenthesis, right parenthesis, and single quotes.<br/>        :String Literals:<br/>            A double quote (``&quot;``) followed by any (including zero) amount of<br/>            characters which are not a double quote. The double quote<br/>            character ends a string, *unless* a backslash precedes it. These<br/>            string literals should be parsed by the ``parse_strlit`` function<br/>            before they are emitted by the lexer.<br/>        :Integer Literals:<br/>            An optional negative sign, followed by 1 or more digits. There cannot<br/>            be a period following the digits, as it should be parsed as a floating<br/>            point number (see below). This should be emitted as Python&#x27;s ``int``<br/>            type.<br/>        :Floating Point Literals:<br/>            An optional negative sign, followed by zero or more digits, followed<br/>            by a period (decimal point), followed by zero or more digits. All<br/>            floating point numbers must have at least one digit. These should be<br/>            emitted as Python&#x27;s ``float`` type.<br/>        :Symbols:<br/>            These are a collection of 1 or more of **any characters**, not<br/>            including single/double quotes, parenthesis, semicolons, or<br/>            whitespace. In addition, symbols cannot start with digits or<br/>            periods.<br/>    <br/>        The following are ignored, and not omitted by the lexer:<br/>    <br/>        :Whitespace:<br/>            Groups of whitespace characters in-between tokens.<br/>        :Comments:<br/>            A semicolon, followed by any amount of characters until the end<br/>            of a line.<br/>        :Shebang Lines:<br/>            A line at the top of the file which starts with ``#!``. For example::<br/>    <br/>                #!/usr/bin/env slyther<br/>    <br/>            Note that it only a shebang line if it&#x27;s at the top of the file.<br/>            Elsewhere, this would look like two symbols.<br/>    <br/>        Anything which does not match above should raise a ``SyntaxError``. Think<br/>        for a second: what might not match the above?<br/>    <br/>        That&#x27;s the end of the technical specification... what follows is examples<br/>        which reading may give you an idea on what to do here.<br/>    <br/>        Strings should be parsed using ``parse_strlit``:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(r&#x27;(print &quot;hello \&quot;world\&quot;!&quot;)&#x27;))<br/>        &gt;&gt;&gt; toks<br/>        [LParen, print, &quot;hello \&quot;world\&quot;!&quot;, RParen]<br/>        &gt;&gt;&gt; type(toks[1])<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>        &gt;&gt;&gt; type(toks[2])<br/>        &lt;class &#x27;slyther.types.String&#x27;&gt;<br/>    <br/>        Symbols are defined based on what characters cannot be in them, not which<br/>        can. This means you can have symbols like this:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;lambda-is-λ ¯\_[ツ]_/¯&#x27;))<br/>        [lambda-is-λ, ¯\_[ツ]_/¯]<br/>    <br/>        Since symbols cannot start with a digit, this function should separate the<br/>        numerical literal from the symbol when things like this happen:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print 8-dogcows)&#x27;))<br/>        [LParen, print, 8, -dogcows, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;(print -8.0-dogcows)&#x27;))<br/>        [LParen, print, -8.0, -dogcows, RParen]<br/>    <br/>        And since symbols can have digits and dots in the middle, make sure these<br/>        are parsed properly:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print dogcows-8.0)&#x27;))<br/>        [LParen, print, dogcows-8.0, RParen]<br/>    <br/>        Quotes can&#x27;t occur in the middle of symbols and numbers, so these quotes<br/>        separate the tokens below, even without whitespace:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(print&#x27;hello-world&#x27;4&#x27;8.0)&quot;))<br/>        [LParen, print, Quote, hello-world, Quote, 4, Quote, 8.0, RParen]<br/>    <br/>        Shebang lines **only at the front of the string, before any whitespace**<br/>        should be ignored, and not emitted as a token:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;#!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;#!slyther\n(print 1)&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot; #!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [#!/usr/bin/env, slyther, LParen, print, 1, RParen]<br/>    <br/>        Comments start at a semicolon and go until the end of line (or,<br/>        potentially the end of the input string). Note that string literals<br/>        might contain semicolons: these don&#x27;t start a comment, beware.<br/>        Comments should not be emitted from the lexer.<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(here-comes; a comment!\n &quot;no comment ; here&quot;;comment()\n)&#x27;))<br/>        [LParen, here-comes, &quot;no comment ; here&quot;, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;; commments can contain ; inside them\n&#x27;))<br/>        []<br/>    <br/>        When an error is encountered, ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;(print &quot;Hello, World!\&quot;)&#x27;))        # unclosed string<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>        &gt;&gt;&gt; list(lex(r&#x27;.symbol&#x27;))        # symbols cannot start with period<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>    <br/>        Don&#x27;t worry about handling unmatched parenthesis or single quotes in an<br/>        invalid position. This will be the parser&#x27;s job! In other words, the<br/>        lexer should be no smarter than it needs to be to do its job.<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(((&quot;))<br/>        [LParen, LParen, LParen]<br/>        &gt;&gt;&gt; list(lex(&quot;(&#x27;)&quot;))<br/>        [LParen, Quote, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;&#x27;&quot;))<br/>        [Quote]<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:211: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_invalid_period(s=&#x27;.&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_lexer_slow.py::test_token_sequences</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">def test_token_sequences():<br/>        for tokens in token_sequences:<br/>            for code in reprs(tokens):<br/>&gt;               result = list(lex(code))<br/><br/>tests\d2\test_lexer_slow.py:78: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>code = &#x27;( ( ( ( ( (&#x27;<br/><br/>    def lex(code):<br/>        r&quot;&quot;&quot;<br/>        IMPORTANT: read this entire docstring before implementing this function!<br/>        Please ask for help on Piazza or come to office hours if you don&#x27;t<br/>        understand something in here.<br/>    <br/>        This is a *generator function* that splits a piece of code into<br/>        lexical tokens, emitting whole tokens each time one is encountered.<br/>    <br/>        A lexical token is not just a string: this function should assign a<br/>        type to each piece of data as appropriate.<br/>    <br/>        For a high level overview, consider this invocation:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(&quot;(define (do-123 fun) \n (map fun &#x27;(1 2 3.0))) \n&quot;))<br/>        &gt;&gt;&gt; toks    # doctest: +NORMALIZE_WHITESPACE<br/>        [LParen, define, LParen, do-123, fun, RParen,<br/>            LParen, map, fun, Quote, LParen, 1, 2, 3.0, RParen, RParen, RParen]<br/>    <br/>        Let&#x27;s look at the types of each piece of data here. The ``LParen``,<br/>        ``RParen``, and ``Quote`` bits are *instances of* the subclasses of<br/>        the ``ControlToken`` class above. ``1`` and ``2`` are Python integers,<br/>        and ``3.0`` is a Python ``float``. Finally, everything else here is a<br/>        ``Symbol``.<br/>    <br/>        &gt;&gt;&gt; print(*(t.__class__.__name__ for t in toks))<br/>        ...                                 # doctest: +NORMALIZE_WHITESPACE<br/>        LParen Symbol LParen Symbol Symbol RParen<br/>        LParen Symbol Symbol Quote LParen int int float RParen RParen RParen<br/>    <br/>        So what goes into this process? First, we need a pretty good definition<br/>        of each of the tokens in the language. The lexer will emit what matches<br/>        the following:<br/>    <br/>        :Control Tokens:<br/>            Left parenthesis, right parenthesis, and single quotes.<br/>        :String Literals:<br/>            A double quote (``&quot;``) followed by any (including zero) amount of<br/>            characters which are not a double quote. The double quote<br/>            character ends a string, *unless* a backslash precedes it. These<br/>            string literals should be parsed by the ``parse_strlit`` function<br/>            before they are emitted by the lexer.<br/>        :Integer Literals:<br/>            An optional negative sign, followed by 1 or more digits. There cannot<br/>            be a period following the digits, as it should be parsed as a floating<br/>            point number (see below). This should be emitted as Python&#x27;s ``int``<br/>            type.<br/>        :Floating Point Literals:<br/>            An optional negative sign, followed by zero or more digits, followed<br/>            by a period (decimal point), followed by zero or more digits. All<br/>            floating point numbers must have at least one digit. These should be<br/>            emitted as Python&#x27;s ``float`` type.<br/>        :Symbols:<br/>            These are a collection of 1 or more of **any characters**, not<br/>            including single/double quotes, parenthesis, semicolons, or<br/>            whitespace. In addition, symbols cannot start with digits or<br/>            periods.<br/>    <br/>        The following are ignored, and not omitted by the lexer:<br/>    <br/>        :Whitespace:<br/>            Groups of whitespace characters in-between tokens.<br/>        :Comments:<br/>            A semicolon, followed by any amount of characters until the end<br/>            of a line.<br/>        :Shebang Lines:<br/>            A line at the top of the file which starts with ``#!``. For example::<br/>    <br/>                #!/usr/bin/env slyther<br/>    <br/>            Note that it only a shebang line if it&#x27;s at the top of the file.<br/>            Elsewhere, this would look like two symbols.<br/>    <br/>        Anything which does not match above should raise a ``SyntaxError``. Think<br/>        for a second: what might not match the above?<br/>    <br/>        That&#x27;s the end of the technical specification... what follows is examples<br/>        which reading may give you an idea on what to do here.<br/>    <br/>        Strings should be parsed using ``parse_strlit``:<br/>    <br/>        &gt;&gt;&gt; toks = list(lex(r&#x27;(print &quot;hello \&quot;world\&quot;!&quot;)&#x27;))<br/>        &gt;&gt;&gt; toks<br/>        [LParen, print, &quot;hello \&quot;world\&quot;!&quot;, RParen]<br/>        &gt;&gt;&gt; type(toks[1])<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>        &gt;&gt;&gt; type(toks[2])<br/>        &lt;class &#x27;slyther.types.String&#x27;&gt;<br/>    <br/>        Symbols are defined based on what characters cannot be in them, not which<br/>        can. This means you can have symbols like this:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;lambda-is-λ ¯\_[ツ]_/¯&#x27;))<br/>        [lambda-is-λ, ¯\_[ツ]_/¯]<br/>    <br/>        Since symbols cannot start with a digit, this function should separate the<br/>        numerical literal from the symbol when things like this happen:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print 8-dogcows)&#x27;))<br/>        [LParen, print, 8, -dogcows, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;(print -8.0-dogcows)&#x27;))<br/>        [LParen, print, -8.0, -dogcows, RParen]<br/>    <br/>        And since symbols can have digits and dots in the middle, make sure these<br/>        are parsed properly:<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(print dogcows-8.0)&#x27;))<br/>        [LParen, print, dogcows-8.0, RParen]<br/>    <br/>        Quotes can&#x27;t occur in the middle of symbols and numbers, so these quotes<br/>        separate the tokens below, even without whitespace:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(print&#x27;hello-world&#x27;4&#x27;8.0)&quot;))<br/>        [LParen, print, Quote, hello-world, Quote, 4, Quote, 8.0, RParen]<br/>    <br/>        Shebang lines **only at the front of the string, before any whitespace**<br/>        should be ignored, and not emitted as a token:<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;#!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;#!slyther\n(print 1)&quot;))<br/>        [LParen, print, 1, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot; #!/usr/bin/env slyther\n(print 1)\n&quot;))<br/>        [#!/usr/bin/env, slyther, LParen, print, 1, RParen]<br/>    <br/>        Comments start at a semicolon and go until the end of line (or,<br/>        potentially the end of the input string). Note that string literals<br/>        might contain semicolons: these don&#x27;t start a comment, beware.<br/>        Comments should not be emitted from the lexer.<br/>    <br/>        &gt;&gt;&gt; list(lex(&#x27;(here-comes; a comment!\n &quot;no comment ; here&quot;;comment()\n)&#x27;))<br/>        [LParen, here-comes, &quot;no comment ; here&quot;, RParen]<br/>        &gt;&gt;&gt; list(lex(&#x27;; commments can contain ; inside them\n&#x27;))<br/>        []<br/>    <br/>        When an error is encountered, ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; list(lex(r&#x27;(print &quot;Hello, World!\&quot;)&#x27;))        # unclosed string<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>        &gt;&gt;&gt; list(lex(r&#x27;.symbol&#x27;))        # symbols cannot start with period<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: malformed tokens in input<br/>    <br/>        Don&#x27;t worry about handling unmatched parenthesis or single quotes in an<br/>        invalid position. This will be the parser&#x27;s job! In other words, the<br/>        lexer should be no smarter than it needs to be to do its job.<br/>    <br/>        &gt;&gt;&gt; list(lex(&quot;(((&quot;))<br/>        [LParen, LParen, LParen]<br/>        &gt;&gt;&gt; list(lex(&quot;(&#x27;)&quot;))<br/>        [LParen, Quote, RParen]<br/>        &gt;&gt;&gt; list(lex(&quot;&#x27;&quot;))<br/>        [Quote]<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:211: NotImplementedError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_valid_parses</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@settings(deadline=None)<br/>&gt;   @given(ast_lists)<br/>    def test_valid_parses(ast):<br/><br/>tests\d2\test_parser.py:52: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_parser.py:54: in test_valid_parses<br/>    assert list(parse(deparse(ast))) == ast<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;generator object deparse at 0x0000020296472ED0&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_valid_parses(ast=[])</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_missing_rp</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">def test_missing_rp():<br/>&gt;       parser = parse(iter([lp, rp, lp, lp, rp]))<br/><br/>tests\d2\test_parser.py:58: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;list_iterator object at 0x000002029652FE48&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_missing_lp</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">def test_missing_lp():<br/>&gt;       parser = parse(iter([10, rp]))<br/><br/>tests\d2\test_parser.py:65: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;list_iterator object at 0x000002029652E710&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_bad_quotation_end</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">def test_bad_quotation_end():<br/>&gt;       parser = parse(iter([q, -15, q, q]))<br/><br/>tests\d2\test_parser.py:72: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;list_iterator object at 0x0000020296572748&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_bad_quotation_rp</td>
          <td class="col-duration">0.00</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">def test_bad_quotation_rp():<br/>&gt;       parser = parse(iter([q, s(&#x27;a&#x27;), lp, q, q, q, rp]))<br/><br/>tests\d2\test_parser.py:79: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;list_iterator object at 0x000002029656E978&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/></div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_parser.py::test_many_quotes</td>
          <td class="col-duration">0.01</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@settings(deadline=None)<br/>&gt;   @given(st.integers(min_value=1, max_value=75))<br/>    def test_many_quotes(quotes):<br/><br/>tests\d2\test_parser.py:86: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_parser.py:88: in test_many_quotes<br/>    parser = parse(iter([q] * quotes + [lp, rp]))<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tokens = &lt;list_iterator object at 0x0000020296588320&gt;<br/><br/>    def parse(tokens):<br/>        r&quot;&quot;&quot;<br/>        This *generator function* takes a generator object from the ``lex``<br/>        function and generates AST elements.<br/>    <br/>        These are some convenient constants to make the examples more readable.<br/>        Make a note of them while you read the examples.<br/>    <br/>        &gt;&gt;&gt; from slyther.types import (Symbol as s, Quoted, SExpression)<br/>        &gt;&gt;&gt; lp = LParen()<br/>        &gt;&gt;&gt; rp = RParen()<br/>        &gt;&gt;&gt; q = Quote()<br/>    <br/>        Here is a simple example:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, s(&#x27;define&#x27;), lp, s(&#x27;do-123&#x27;), s(&#x27;fun&#x27;), rp,<br/>        ...             lp, s(&#x27;map&#x27;), s(&#x27;fun&#x27;), q, lp, 1, 2, 3, rp, rp, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; se = next(parser)<br/>        &gt;&gt;&gt; se                  # what you see below is from __repr__<br/>        (define (do-123 fun) (map fun &#x27;(1 2 3)))<br/>        &gt;&gt;&gt; type(se)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>        &gt;&gt;&gt; type(se.car)<br/>        &lt;class &#x27;slyther.types.Symbol&#x27;&gt;<br/>    <br/>        Let&#x27;s grab out that quoted list and take a look at it.<br/>    <br/>        &gt;&gt;&gt; quoted_list = se.cdr.cdr.car.cdr.cdr.car<br/>        &gt;&gt;&gt; quoted_list<br/>        &#x27;(1 2 3)<br/>        &gt;&gt;&gt; type(quoted_list)<br/>        &lt;class &#x27;slyther.types.Quoted&#x27;&gt;<br/>        &gt;&gt;&gt; type(quoted_list.elem)<br/>        &lt;class &#x27;slyther.types.SExpression&#x27;&gt;<br/>    <br/>        It was a quoted s-expression. Those can be constructed like this:<br/>    <br/>        &gt;&gt;&gt; Quoted(SExpression.from_iterable([1, 2, 3]))<br/>        &#x27;(1 2 3)<br/>    <br/>        Not only can s-expressions be quoted, but practically anything can. In<br/>        addition, things can be quoted multiple times.<br/>    <br/>        &gt;&gt;&gt; tokens = [q, lp, s(&#x27;print&#x27;), 1, q, -2, q, q, 3.0, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; qse = next(parser)<br/>        &gt;&gt;&gt; qse<br/>        &#x27;(print 1 &#x27;-2 &#x27;&#x27;3.0)<br/>        &gt;&gt;&gt; numbers = qse.elem.cdr<br/>        &gt;&gt;&gt; numbers<br/>        (1 &#x27;-2 &#x27;&#x27;3.0)<br/>    <br/>        See that doubly-quoted three? It was constructed like this:<br/>    <br/>        &gt;&gt;&gt; three = Quoted(Quoted(3.0))<br/>        &gt;&gt;&gt; three<br/>        &#x27;&#x27;3.0<br/>        &gt;&gt;&gt; three.elem<br/>        &#x27;3.0<br/>        &gt;&gt;&gt; three.elem.elem<br/>        3.0<br/>    <br/>        You could imagine something similar for triply-quoted, quad-quoted, or<br/>        even n-quoted. Your parser should be able to handle any amount of quotes.<br/>    <br/>        When the input token stream is starting to form a valid parse, but ends<br/>        before the parse is complete, a ``SyntaxError`` should be raised:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, lp, s(&#x27;print&#x27;)]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, q]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: incomplete parse<br/>    <br/>        Notice in both of the previous examples, we got complete elements as soon<br/>        as they were fully formed, and the syntax error did not come until there<br/>        was an error.<br/>    <br/>        When there&#x27;s too many closing parens, you should raise another error:<br/>    <br/>        &gt;&gt;&gt; tokens = [lp, rp, s(&#x27;print&#x27;), rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        NIL<br/>        &gt;&gt;&gt; next(parser)<br/>        print<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: too many closing parens<br/>    <br/>        Finally, right parenthesis cannot be quoted. We have one more type of<br/>        error this can raise:<br/>    <br/>        &gt;&gt;&gt; tokens = [q, 1, lp, s(&#x27;print&#x27;), q, rp]<br/>        &gt;&gt;&gt; parser = parse(iter(tokens))<br/>        &gt;&gt;&gt; next(parser)<br/>        &#x27;1<br/>        &gt;&gt;&gt; next(parser)<br/>        Traceback (most recent call last):<br/>            ...<br/>        SyntaxError: invalid quotation<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:398: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_many_quotes(quotes=1)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_pycompat_escapes</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;(\\[abfnrtv&quot;\\]|[^&quot;\\])*&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_pycompat_escapes(s):<br/><br/>tests\d2\test_strlit.py:9: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:10: in test_pycompat_escapes<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_pycompat_escapes(s=&#x27;&quot;&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_replacement_escapes</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;(\\[0e]|[^0-9&quot;\\])*&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_replacement_escapes(s):<br/><br/>tests\d2\test_strlit.py:16: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:17: in test_replacement_escapes<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_replacement_escapes(s=&#x27;&quot;&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_octal</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;\\0[0-7][0-7]&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_octal(s):<br/><br/>tests\d2\test_strlit.py:23: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:24: in test_octal<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;\\000&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_octal(s=&#x27;&quot;\\000&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_bad_octal</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;\\0[89][89]&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_bad_octal(s):<br/><br/>tests\d2\test_strlit.py:31: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:32: in test_bad_octal<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;\\088&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_bad_octal(s=&#x27;&quot;\\088&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_hex</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;\\x[0-9A-Fa-f][0-9A-Fa-f]&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_hex(s):<br/><br/>tests\d2\test_strlit.py:38: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:39: in test_hex<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;\\x00&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_hex(s=&#x27;&quot;\\x00&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_bad_hex</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;\\x[G-Zg-z][A-Za-z0-9]&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_bad_hex(s):<br/><br/>tests\d2\test_strlit.py:46: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:47: in test_bad_hex<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;\\xG0&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_bad_hex(s=&#x27;&quot;\\xG0&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_bad_hex_cap</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;\\X[0-9A-Fa-f][0-9A-Fa-f]&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_bad_hex_cap(s):<br/><br/>tests\d2\test_strlit.py:53: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:54: in test_bad_hex_cap<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;\\X00&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_bad_hex_cap(s=&#x27;&quot;\\X00&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_nocaps</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;(\\[A-Z]|[^&quot;\\])*&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_nocaps(s):<br/><br/>tests\d2\test_strlit.py:60: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:61: in test_nocaps<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_nocaps(s=&#x27;&quot;&quot;&#x27;)</div></td></tr></tbody>
      <tbody class="failed results-table-row">
        <tr>
          <td class="col-result">Failed</td>
          <td class="col-name">tests/d2/test_strlit.py::test_nobadlower</td>
          <td class="col-duration">0.02</td>
          <td class="col-links"></td></tr>
        <tr>
          <td class="extra" colspan="4">
            <div class="log">@given(st.from_regex(r&#x27;&quot;(\\[cdghijklmopqsuwyz]|[^&quot;\\])*&quot;&#x27;, fullmatch=True))<br/>&gt;   def test_nobadlower(s):<br/><br/>tests\d2\test_strlit.py:67: <br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/>tests\d2\test_strlit.py:68: in test_nobadlower<br/>    result = parse_strlit(s)<br/>_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _<br/><br/>tok = &#x27;&quot;&quot;&#x27;<br/><br/>    def parse_strlit(tok):<br/>        r&quot;&quot;&quot;<br/>        This function is a helper method for ``lex``. It takes a string literal,<br/>        raw, just like it is in the source code, and converts it to a<br/>        ``slyther.types.String``.<br/>    <br/>        It should support the following translations:<br/>    <br/>        +-----------------+--------------------+<br/>        | Escape Sequence | Resulting Output   |<br/>        +=================+====================+<br/>        | ``\0``          | ASCII Value 0      |<br/>        +-----------------+--------------------+<br/>        | ``\a``          | ASCII Value 7      |<br/>        +-----------------+--------------------+<br/>        | ``\b``          | ASCII Value 8      |<br/>        +-----------------+--------------------+<br/>        | ``\e``          | ASCII Value 27     |<br/>        +-----------------+--------------------+<br/>        | ``\f``          | ASCII Value 12     |<br/>        +-----------------+--------------------+<br/>        | ``\n``          | ASCII Value 10     |<br/>        +-----------------+--------------------+<br/>        | ``\r``          | ASCII Value 13     |<br/>        +-----------------+--------------------+<br/>        | ``\t``          | ASCII Value 9      |<br/>        +-----------------+--------------------+<br/>        | ``\v``          | ASCII Value 11     |<br/>        +-----------------+--------------------+<br/>        | ``\&quot;``          | ASCII Value 34     |<br/>        +-----------------+--------------------+<br/>        | ``\\``          | ASCII Value 92     |<br/>        +-----------------+--------------------+<br/>        | ``\x##``        | Hex value ``##``   |<br/>        +-----------------+--------------------+<br/>        | ``\0##``        | Octal value ``##`` |<br/>        +-----------------+--------------------+<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\0&quot;&#x27;)<br/>        &quot;\x00&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\e&quot;&#x27;)<br/>        &quot;\x1b&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x41&quot;&#x27;)<br/>        &quot;A&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\x53\x6c\x79\x74\x68\x65\x72\x4C\x69\x73\x70&quot;&#x27;)<br/>        &quot;SlytherLisp&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;this is my\&quot; fancy\n\estring literal&quot;&#x27;)<br/>        &quot;this is my\&quot; fancy\n\x1bstring literal&quot;<br/>    <br/>        Patterns which do not match the translations should be left alone:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\c\d\xzz&quot;&#x27;)<br/>        &quot;\\c\\d\\xzz&quot;<br/>    <br/>        Octal values should only expand when octal digits (0-7) are used:<br/>    <br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\077&quot;&#x27;)<br/>        &quot;?&quot;<br/>        &gt;&gt;&gt; parse_strlit(r&#x27;&quot;\088&quot;&#x27;) # a \0, followed by two 8&#x27;s<br/>        &quot;\x0088&quot;<br/>    <br/>        Even though this is similar to Python&#x27;s string literal format,<br/>        you should not use any of Python&#x27;s string literal processing<br/>        utilities for this: tl;dr do it yourself.<br/>        &quot;&quot;&quot;<br/>&gt;       raise NotImplementedError(&quot;Deliverable 2&quot;)<br/><span class="error">E       NotImplementedError: Deliverable 2</span><br/><br/>c:\users\steve\mines-courses\mines courses\csci_400\slytherlisp\slyther\parser.py:279: NotImplementedError<br/>---------------------------------- Hypothesis ----------------------------------<br/>Falsifying example: test_nobadlower(s=&#x27;&quot;&quot;&#x27;)</div></td></tr></tbody></table></body></html>