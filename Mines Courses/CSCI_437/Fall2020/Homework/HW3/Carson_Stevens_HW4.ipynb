{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"description user_content student-version enhanced\"><div id=\"content\">\n",
    "<h1 class=\"title\">Quick Reference</h1>\n",
    "<div id=\"outline-container-orgheadline1\" class=\"outline-2\">\n",
    "<div id=\"text-orgheadline1\" class=\"outline-text-2\">\n",
    "<ul class=\"org-ul\">\n",
    "<li>Due date:&nbsp;<strong>Wednesday, October 14th</strong> by 11:59PM.</li>\n",
    "<li>Submission: Submission must be made on Canvas</li>\n",
    "<li>Format: Your submission will consist of two files: a Python file (or tar/zip/archive of code), and (2) a PDF file. Please upload these as two&nbsp;<strong>separate files</strong>&nbsp;– do not group both code and report into the same tar/zip/archive.</li>\n",
    "</ul>\n",
    "</div>\n",
    "</div>\n",
    "<div id=\"outline-container-orgheadline2\" class=\"outline-2\">\n",
    "<h2 id=\"orgheadline2\">\n",
    "<span class=\"section-number-2\"></span>Questions</h2>\n",
    "<div id=\"text-1\" class=\"outline-text-2\">\n",
    "<p title=\"Play media comment.\">The video <a id=\"media_comment_maybe\" class=\"instructure_file_link instructure_video_link\" title=\"fiveCCC.mp4\" href=\"/courses/25410/files/2220857/download?wrap=1\">fiveCCC.mp4</a> shows a target composed of five concentric contrasting circle (CCC) features. The dimensions of the target (in inches) are shown in the figure below. The origin of the target’s coordinate system is in the middle of the rectangle, with its x-axis pointing to the right, its y-axis pointing down, and its z-axis pointing into the page.</p>\n",
    "<div class=\"figure\">\n",
    "<p><img src=\"http://inside.mines.edu/~twilliams/courses/CV-507/hw3image0.png\" alt=\"hw3image0.png\" style=\"max-width: 400px;\"></p>\n",
    "</div>\n",
    "<ol class=\"org-ol\">\n",
    "<li>Read and display each image of the video, and print the frame number on the displayed image.</li>\n",
    "<li>Write a program that finds the five CCCs in each image, and also finds the correspondence between the image features and the model features.</li>\n",
    "<li>Find a picture that you like and map it onto the target plane in each image, using a homography (projective transform). The picture should look like it is attached to the plane of the target.</li>\n",
    "<li>Find the pose of the target with respect to the camera in each frame of the video. Draw the XYZ coordinate axes of the target as an overlay on the image, and also print the pose values on the image, in terms of translation (in inches) and the rotation vector.</li>\n",
    "<li>Create an output video of your results, and post it to Google Drive.</li>\n",
    "</ol>\n",
    "<p>Use the following values for the camera intrinsic parameters: focal length = 531 (in pixels), image center (x,y in pixels) = (320, 240).&nbsp; Assume no lens distortion.</p>\n",
    "<p>An example output image is shown below. I used an image of a dollar bill; you should use something else.</p>\n",
    "<div class=\"figure\">\n",
    "<p><img src=\"https://elearning.mines.edu/courses/25410/files/2219531/download\" alt=\"hw3.png\"style=\"max-width: 643px;\"></p>\n",
    "</div>\n",
    "<p>Turn in:</p>\n",
    "<ol class=\"org-ol\">\n",
    "<li>Your program listing, with comments.</li>\n",
    "<li>A PDF file containing a description of your solution and a link to your video.&nbsp;<strong>Make sure your link is accessible to others by testing it in incognito mode.</strong>\n",
    "</li>\n",
    "</ol>\n",
    "</div>\n",
    "</div>\n",
    "</div></div>\n",
    "\n",
    "<div>\n",
    "    <h1>Solution</h1>\n",
    "    <h2>Description</h2>\n",
    "    <p>\n",
    "        The program starts by applying an adaptive gaussian threshold with a block size of 9 (similar to the size in pixels of the CCC (not sure if that is a coincident, but was the threshold that worked best). Then the image and inverse image are processed with openings, closings, erosion, and dilation to maximize the targets. This process what visualized by viewing the inner and outer connected component labels. The found targets then go through the process for finding CCCs (checking centroid distance, area, etc. I also added a function to reject outlier points that didn't fit the std of the rest of the points). 5 points were detected in each frame with the current settings, so I assumed the pose would also be found in all the frames. Unfortunately, the last 4 frame before the last frame failed to find the pose which can be seen in the printed error percentage.<br><br>So once 5 points were found, these were passed to the order_targets function and then to the solvePnP function to find the pose, rotation vector and translation vector. If the pose was found, the axis and labels are drawn. Finally, the coordinates for CCC labels 0, 2, 3, and 4 were passed as bounds for the planes replacement. Given the bounds, the source image's (BK logo) perspective is warped to match the region of interest and masks are applied to replace the image in that location. Problems encountered here were when the coordinates form a diamond shape where the top and bottom points have close to the same x value or right and left have close to the same y value, the cv2 function for replacing the rectangle creates a weird visual effect because the angles are 'extreme' and the warped image doesn't understand the orientation its supposed to be placed in. The other problem I encountered was trying to rotate the image when the CCCs are rotated around the Z axis. Since I was grabbing the rotation for Z from the solvePnP function, I thought that I would be able to flip the image based off of that parameter, but the pose was so shaky around some of the flip points that the image would start flipping a bunch simply due to the instabilties and errors in each pose. I ended up removing this portion due to the flickering effect caused by the flipping. This does mean that when he turns the CCCs more that 90 degrees, the CCCs image will flip back to the upright orientation.<br><br>Lastly were all of the add ons, like drawing the frame number, labels, axis, rotation vector, and translation vector. Once those were all done, the image was saved to the output video. Voila.</p>\n",
    "\n",
    "\n",
    "</div><a href=\"https://drive.google.com/file/d/1RAINtJCkrulcbSZvnGXFq2587H18A6Ov/view?usp=sharing\" target=\"_blank\">Here</a> is a link to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T19:41:36.083270Z",
     "start_time": "2020-10-28T19:41:36.014710Z"
    },
    "code_folding": [
     24,
     35,
     53,
     86,
     97,
     124,
     201
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# For displaying\n",
    "import IPython.display\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def imdisplay(img, fmt='jpeg', width=500, bgr=True):\n",
    "    f = BytesIO()\n",
    "    if bgr:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    new_p = PIL.Image.fromarray(img.astype(np.uint8))\n",
    "    new_p.save(f, fmt)\n",
    "    return IPython.display.Image(data=f.getvalue(), width=width)\n",
    "\n",
    "\n",
    "# URL to cv2 img\n",
    "def url_to_image(url):\n",
    "    # download the image, convert it to a NumPy array, and then read\n",
    "    # it into OpenCV format\n",
    "    resp = urllib.request.urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    # return the image\n",
    "    return image\n",
    "\n",
    "\n",
    "# Color the connected components\n",
    "def color_components(labels):\n",
    "    # Map component labels to hue val\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # cvt to BGR for display\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # set bg label to black\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "    return labeled_img\n",
    "\n",
    "\n",
    "def getIntrinsicCamMatrix(f, sx, sy, center=[0, 0]):\n",
    "    return np.array([[f/sx, 0, center[0]], [0, f/sy, center[1]], [0, 0, 1]])\n",
    "\n",
    "\n",
    "def findCCCPoints(innerComponents, outerComponents):\n",
    "    pts = []\n",
    "    distance_threshold = 4\n",
    "    num_labels_inner, labels_im_inner, innerStats, innerCentroids = cv2.connectedComponentsWithStats(\n",
    "        innerComponents, connectivity=8)\n",
    "    color_labeled_img_inner = color_components(labels_im_inner)\n",
    "    d2.update(imdisplay(color_labeled_img_inner))\n",
    "\n",
    "    num_labels_outer, labels_im_outer, outerStats, outerCentroids = cv2.connectedComponentsWithStats(\n",
    "        outerComponents, connectivity=4)\n",
    "    color_labeled_img_outer = color_components(labels_im_outer)\n",
    "    d3.update(imdisplay(color_labeled_img_outer))\n",
    "\n",
    "    for i, i_centroid in enumerate(innerCentroids):\n",
    "        if (i == 0):\n",
    "            continue\n",
    "        for j, o_centroid in enumerate(outerCentroids):\n",
    "            if (j == 0):\n",
    "                continue\n",
    "            xi = int(i_centroid[0])\n",
    "            yi = int(i_centroid[1])\n",
    "            xo = int(o_centroid[0])\n",
    "            yo = int(o_centroid[1])\n",
    "            if(np.abs(xi - xo) < distance_threshold and\n",
    "               np.abs(yi - yo) < distance_threshold):\n",
    "                #                 Check Area\n",
    "                if(innerStats[i][4] < outerStats[j][4]):\n",
    "                    if (True or outerStats[j][3] - innerStats[i][3] > 0 and outerStats[j][2] - innerStats[i][2] > 0):\n",
    "                        pts.append([xi, yi])\n",
    "    if (len(pts) > 5): pts = reject_outliers(pts)\n",
    "    return pts\n",
    "\n",
    "\n",
    "def reject_outliers(data, m=1.25):\n",
    "    x_vec, y_vec = np.split(data, [-1], 1)\n",
    "    valid_pts = []\n",
    "    for point in data:\n",
    "        if (np.abs(point[0] - np.mean(x_vec)) < m * np.std(x_vec) and\n",
    "                np.abs(point[1] - np.mean(y_vec)) < m * np.std(y_vec)):\n",
    "            valid_pts.append(point)\n",
    "    return valid_pts\n",
    "\n",
    "\n",
    "# Order Points Clockwise and return rect bounds\n",
    "def order_points(pts):\n",
    "    # initialize a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "\n",
    "# This function tries to find the 5-target pattern that looks like this\n",
    "#  0  1  2\n",
    "#  3     4\n",
    "# The input is a list of (x,y) locations of possible targets, where each location is\n",
    "# a numpy array of length 2. The output is a list of 5 targets in the proper order.\n",
    "# If 5 targets in the correct configuration is not found, it returns an empty list.\n",
    "def order_targets(allTargets):\n",
    "    orderedTargets = []\n",
    "    nTargets = len(allTargets)\n",
    "    if nTargets < 5:\n",
    "        return orderedTargets\n",
    "\n",
    "    # Find 3 targets that are in a line.\n",
    "    dMin = 1e9  # distance from a point to the midpt between points 1,3\n",
    "    d02 = 0     # distance between points 1,3\n",
    "    for i in range(0, nTargets):\n",
    "        for j in range(i+1, nTargets):\n",
    "            # Get the mid point between i,j.\n",
    "            midPt = (allTargets[i] + allTargets[j])/2\n",
    "\n",
    "            # Find another target that is closest to this midpoint.\n",
    "            for k in range(0, nTargets):\n",
    "                if k == i or k == j:\n",
    "                    continue\n",
    "                # distance from midpoint\n",
    "                d = np.linalg.norm(allTargets[k] - midPt)\n",
    "                if d < dMin:\n",
    "                    dMin = d        # This is the minimum found so far; save it\n",
    "                    i0 = i\n",
    "                    i1 = k\n",
    "                    i2 = j\n",
    "                    d02 = np.linalg.norm(allTargets[i0] - allTargets[i2])\n",
    "\n",
    "    # If the best distance from the midpoint is < 30% of the distance between\n",
    "    # the two other points, then we probably have a colinear set; otherwise not.\n",
    "    if dMin / d02 > 0.3:\n",
    "        return orderedTargets   # return an empty list\n",
    "\n",
    "    # We have found 3 colinear targets:  p0 -- p1 -- p2.\n",
    "    # Now find the one closest to p0; call it p3.\n",
    "    i3 = findClosest(allTargets, i0, excluded=[i0, i1, i2])\n",
    "    if i3 is None:\n",
    "        return []  # return an empty list\n",
    "\n",
    "    # Now find the one closest to p2; call it p4.\n",
    "    i4 = findClosest(allTargets, i2, excluded=[i0, i1, i2, i3])\n",
    "    if i4 is None:\n",
    "        return []  # return an empty list\n",
    "\n",
    "    # Now, check to see where p4 is with respect to p0,p1,p2.  If the\n",
    "    # signed area of the triangle p0-p2-p3 is negative, then we have\n",
    "    # the correct order; ie\n",
    "    #   0   1   2\n",
    "    #   3\t\t4\n",
    "    # Otherwise we need to switch the order; ie\n",
    "    #   2\t1\t0\n",
    "    #   4\t\t3\n",
    "\n",
    "    # Signed area is the determinant of the 2x2 matrix [ p3-p0, p2-p0 ].\n",
    "    p30 = allTargets[i3] - allTargets[i0]\n",
    "    p20 = allTargets[i2] - allTargets[i0]\n",
    "    M = np.array([[p30[0], p20[0]], [p30[1], p20[1]]])\n",
    "    det = np.linalg.det(M)\n",
    "\n",
    "    # Put the targets into the output list.\n",
    "    if det < 0:\n",
    "        orderedTargets.append(allTargets[i0])\n",
    "        orderedTargets.append(allTargets[i1])\n",
    "        orderedTargets.append(allTargets[i2])\n",
    "        orderedTargets.append(allTargets[i3])\n",
    "        orderedTargets.append(allTargets[i4])\n",
    "    else:\n",
    "        orderedTargets.append(allTargets[i2])\n",
    "        orderedTargets.append(allTargets[i1])\n",
    "        orderedTargets.append(allTargets[i0])\n",
    "        orderedTargets.append(allTargets[i4])\n",
    "        orderedTargets.append(allTargets[i3])\n",
    "\n",
    "    return orderedTargets\n",
    "\n",
    "\n",
    "# In the list of points \"allPoints\", find the closest point to point i0, that is not\n",
    "# one of the points in the excluded list.  If none found, return None.\n",
    "def findClosest(allPoints, i0, excluded):\n",
    "    dMin = 1e9\n",
    "    iClosest = None\n",
    "    for i in range(0, len(allPoints)):\n",
    "        if i in excluded:\n",
    "            continue\n",
    "        d = np.linalg.norm(allPoints[i] - allPoints[i0])\n",
    "        if d < dMin:\n",
    "            dMin = d\n",
    "            iClosest = i\n",
    "    return iClosest\n",
    "\n",
    "\n",
    "def processFrame(original_img):\n",
    "    temp_img = original_img\n",
    "    thresh_img = cv2.adaptiveThreshold(cv2.cvtColor(temp_img, cv2.COLOR_BGR2GRAY), 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY, 9, 30)\n",
    "    innerComponents, outerComponents = applyMorphology(thresh_img)\n",
    "    return [thresh_img, innerComponents, outerComponents]\n",
    "\n",
    "\n",
    "def applyMorphology(thresh_img):\n",
    "\n",
    "    kernelClose = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "    kernelOpen = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 1))\n",
    "    kernelDilate = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    kernelErode = cv2.getStructuringElement(cv2.MORPH_CROSS, (2, 3))\n",
    "\n",
    "    filtered_img_close = cv2.morphologyEx(\n",
    "        ~thresh_img, cv2.MORPH_CLOSE, kernelClose)\n",
    "    filtered_img_open = cv2.morphologyEx(\n",
    "        filtered_img_close, cv2.MORPH_OPEN, kernelOpen, 1)\n",
    "    outerComponents = filtered_img_open\n",
    "\n",
    "    innerComponents = cv2.dilate(\n",
    "        cv2.erode(thresh_img, kernelErode), kernelDilate)\n",
    "\n",
    "    return [innerComponents, outerComponents]\n",
    "\n",
    "\n",
    "def drawPose(img, text, org=(50, 50)):\n",
    "    # Printing options\n",
    "    # font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # fontScale\n",
    "    font_scale = 0.5\n",
    "    # Blue color in BGR\n",
    "    font_color = (255, 0, 0)\n",
    "    # White background\n",
    "    bg_color = (255, 255, 255)\n",
    "    # Line thickness of 2 px\n",
    "    thickness = 1\n",
    "    ((txt_w, txt_h), _) = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    # Place text background.\n",
    "    back_tl = org[0], org[1] - int(1.3 * txt_h)\n",
    "    back_br = org[0] + txt_w, org[1]\n",
    "    cv2.rectangle(img, back_tl, back_br, bg_color, -1)\n",
    "    # Show text.\n",
    "    txt_tl = org[0], org[1] - int(0.3 * txt_h)\n",
    "    return cv2.putText(img, text, txt_tl, fontFace=font, fontScale=font_scale, color=font_color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "def drawCCCLabels(img, pts, org=(-3, -8)):\n",
    "    # Printing options\n",
    "    # font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # fontScale\n",
    "    font_scale = 0.35\n",
    "    # Blue color in BGR\n",
    "    font_color = (0, 0, 255)\n",
    "    # White background\n",
    "    bg_color = (255, 255, 255)\n",
    "    # Line thickness of 2 px\n",
    "    thickness = 1\n",
    "    for i, point in enumerate(pts):\n",
    "        img = cv2.putText(img, str(i), (int(point[0]+org[0]), int(point[1]+org[1])), fontFace=font,\n",
    "                          fontScale=font_scale, color=font_color, thickness=thickness, lineType=cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "\n",
    "def applyPose(pts, img):\n",
    "    focal_length = 531.0\n",
    "    x_center = 320.0\n",
    "    y_center = 240.0\n",
    "\n",
    "    CCCs_height = 4.55\n",
    "    CCCs_width = 7.4\n",
    "\n",
    "    P_M = np.array([[-CCCs_width / 2, -CCCs_height / 2, 0.0],\n",
    "                    [0.0, -CCCs_height / 2, 0.0],\n",
    "                    [CCCs_width / 2, -CCCs_height / 2, 0.0],\n",
    "                    [-CCCs_width/2, CCCs_height / 2.0, 0.0],\n",
    "                    [CCCs_width / 2, CCCs_height / 2.0, 0.0]])\n",
    "\n",
    "    K = getIntrinsicCamMatrix(focal_length, 1, 1, center=[x_center, y_center])\n",
    "    isPoseFound = False\n",
    "    try:\n",
    "        isPoseFound, rvec, tvec = cv2.solvePnP(objectPoints=P_M.astype(np.float64),  # Numpy array, size (5,3)\n",
    "                                               # Numpy array, size (5,2)\n",
    "                                               imagePoints=pts.astype(\n",
    "                                                   np.float64),\n",
    "                                               cameraMatrix=K.astype(np.float64), distCoeffs=None)\n",
    "    except:\n",
    "        isPoseFound = False\n",
    "    if isPoseFound:\n",
    "\n",
    "        #         print(\"\\n\\nPose Found: \", isPoseFound)\n",
    "        #         print(\"\\n\\nRotation Vector: \", rvec)\n",
    "        #         print(\"\\n\\nTranslation Vector: \", tvec)\n",
    "\n",
    "        # Draw coordinate axes onto the image.  Scale the length of the axes\n",
    "        # according to the size of the model, so that the axes are visible.\n",
    "        # Size of model in X,Y,Z\n",
    "        W = np.amax(P_M, axis=0) - np.amin(P_M, axis=0)\n",
    "        L = np.linalg.norm(W)   # Length of the diagonal of the bounding box\n",
    "        d = L/4  # This will be the length of the coordinate axes\n",
    "        pAxes = np.float32([[0, 0, 0],  # origin\n",
    "                            [d, 0, 0],  # x axis\n",
    "                            [0, d, 0],  # y axis\n",
    "                            [0, 0, d]  # z axis\n",
    "                            ])\n",
    "        pImg, J = cv2.projectPoints(\n",
    "            objectPoints=pAxes, rvec=rvec, tvec=tvec, cameraMatrix=K, distCoeffs=None)\n",
    "\n",
    "        img = replacePlanes(img,  np.array(order_points(np.array([pts[0], pts[2], pts[4], pts[3]])), np.float32))\n",
    "        pImg = pImg.reshape(-1, 2)  # reshape from size (N,1,2) to (N,2)\n",
    "        poseR = f'''RVect: X:{np.round(rvec[0],2)}, Y:{np.round(rvec[1],2)}, Z:{np.round(rvec[2],2)}'''\n",
    "        poseT = f'''TVect: X:{np.round(tvec[0],1)}, Y:{np.round(tvec[1],1)}, Z:{np.round(tvec[2],1)}'''\n",
    "        # pose = f'''RVect: {rvec}, Tvect: {tvec} '''\n",
    "        img = cv2.line(img, tuple(np.int32(pImg[0])), tuple(\n",
    "            np.int32(pImg[1])), (0, 0, 255), 2)  # x red\n",
    "        img = cv2.line(img, tuple(np.int32(pImg[0])), tuple(\n",
    "            np.int32(pImg[2])), (0, 255, 0), 2)  # y green\n",
    "        img = cv2.line(img, tuple(np.int32(pImg[0])), tuple(\n",
    "            np.int32(pImg[3])), (255, 0, 0), 2)  # z blue\n",
    "        img = drawPose(img, poseR, (50, 50))\n",
    "        img = drawPose(img, poseT, (50, 70))\n",
    "        img = drawCCCLabels(img, pts)\n",
    "        \n",
    "    return isPoseFound, img\n",
    "\n",
    "\n",
    "def replacePlanes(dest_img, dest_pts):\n",
    "    global src_img\n",
    "    \n",
    "    src_pts = [[0, 0], [src_img.shape[0], 0], [\n",
    "        src_img.shape[0], src_img.shape[1]], [0, src_img.shape[1]]]\n",
    "    # Alternate if only 4 points\n",
    "    src_pts_ordered = order_points(np.array(src_pts))\n",
    "    dest_pts_ordered = order_points(np.array(dest_pts))\n",
    "    if (int(dest_pts[0][0]) == int(dest_pts[2][0])): dest_pts[2][0] += 1\n",
    "    if (int(dest_pts[1][1]) == int(dest_pts[3][1])): dest_pts[3][1] += 1\n",
    "    # H=cv2.getPerspectiveTransform(src_pts, dest_pts)\n",
    "    H, mask = cv2.findHomography(\n",
    "        src_pts_ordered, dest_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "    # Warp source image to destination based on homography\n",
    "    # size argument is width x height, so have to reverse shape values\n",
    "    src_warped = cv2.warpPerspective(\n",
    "        src_img, H, (dest_img.shape[1], dest_img.shape[0]))\n",
    "\n",
    "    dest_img = cv2.fillConvexPoly(np.array(dest_img, 'int32'), np.array(\n",
    "        dest_pts_ordered, 'int32'), (0, 255, 0))\n",
    "\n",
    "    # Set BGR color ranges\n",
    "    lowerBound = np.array([0, 255, 0])\n",
    "    upperBound = np.array([0, 255, 0])\n",
    "\n",
    "    # Compute mask (roi) from ranges in dst\n",
    "    mask = cv2.inRange(dest_img, lowerBound, upperBound)\n",
    "\n",
    "    # Dilate mask, if needed, when green border shows\n",
    "    # kernel = np.ones((3,3),np.uint8)\n",
    "    # mask = cv2.dilate(mask,kernel,iterations = 1)\n",
    "\n",
    "    # Invert mask\n",
    "    inv_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    # Mask dst with inverted mask\n",
    "    dest_masked = cv2.bitwise_and(dest_img, dest_img, mask=inv_mask)\n",
    "\n",
    "    # Put src_warped over dst\n",
    "    src_warped = cv2.resize(src_warped, dest_masked.shape[1::-1])\n",
    "    result = cv2.bitwise_or(np.float32(dest_masked), np.float32(src_warped))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T19:41:36.239404Z",
     "start_time": "2020-10-28T19:41:36.085771Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d1 = IPython.display.display(\"\", display_id=1)\n",
    "d2 = IPython.display.display(\"\", display_id=2)\n",
    "d3 = IPython.display.display(\"\", display_id=3)\n",
    "d4 = IPython.display.display(\"\", display_id=4)\n",
    "d5 = IPython.display.display(\"\", display_id=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T19:34:19.473021Z",
     "start_time": "2020-10-15T19:33:53.748450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Video\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    video_name = \"fiveCCC.mp4\"\n",
    "    cam = cv2.VideoCapture(video_name)\n",
    "    fps = cam.get(cv2.CAP_PROP_FPS)\n",
    "    frame = 0\n",
    "    poseCounter = 0\n",
    "    total_frames = int(cam.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    src_img = url_to_image(\n",
    "        \"https://play-lh.googleusercontent.com/S3GUKxn95ihjayGjfZcVjx6YMdub723eg1wItYVYZeJya1TMlFPdjPjOWHOJv82VPG7a=s180\")\n",
    "    d1.update(imdisplay(src_img))\n",
    "    rotated = None\n",
    "\n",
    "    video_output_name = video_name[0:video_name.find(\".\")]+\"_output\"+\".mp4\"\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "    videoWriter = cv2.VideoWriter(filename=video_output_name, fourcc=fourcc, fps=fps,\n",
    "                              frameSize=(int(cam.get(3)), int(cam.get(4))))\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            t1 = time.time()\n",
    "            got_image, original_img = cam.read() # Try to read in video\n",
    "            if not got_image: break  # break if no video\n",
    "            frame += 1\n",
    "            thresh_img, innerComponents, outerComponents = processFrame(\n",
    "                original_img)\n",
    "            pts = findCCCPoints(innerComponents, outerComponents)\n",
    "            if (len(pts) == 5):\n",
    "                poseFound, frame_img = applyPose(np.array(order_targets(np.array(pts, np.float32)), np.float64), original_img)\n",
    "                \n",
    "                if poseFound: poseCounter += 1\n",
    "\n",
    "            frame_img=cv2.putText(frame_img, text=str(frame), org=(50, 400), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                       fontScale=1.5, color=(0, 255, 255), thickness=3)\n",
    "            \n",
    "            \n",
    "            c = cv2.waitKey(1)\n",
    "            if c & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "            s=f\"\"\"<h1>Pose Found Rate: {np.round(100*poseCounter/frame, 4)}%<h3>{int(1/(time.time()-t1))} FPS</h3>\"\"\"\n",
    "            d5.update(IPython.display.HTML(s))\n",
    "            d4.update(imdisplay(frame_img, width=900))\n",
    "            newFrame = np.array(PIL.Image.fromarray(frame_img.astype(np.uint8)).convert('RGB'))[:, :, ::-1].copy() \n",
    "            videoWriter.write(cv2.cvtColor(newFrame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cam.release()\n",
    "    videoWriter.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"End of Video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "93.9751px",
    "width": "159.996px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "164.987px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
