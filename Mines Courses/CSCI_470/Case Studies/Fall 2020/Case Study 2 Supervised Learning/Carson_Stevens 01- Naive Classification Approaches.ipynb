{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
    "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
    "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d692812fb40744cf856dd618b340fdab",
     "grade": false,
     "grade_id": "cell-331eb85546d2d12e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Naive Classification Approaches\n",
    "\n",
    "\n",
    "In this case study, we will build a custom classifier that takes some naive classification approaches. The approaches we'll take are:\n",
    "\n",
    "- Guessing a user-determined class at all times\n",
    "- Guessing the most common class at all times\n",
    "- Guessing randomly based on the distribution of the classes\n",
    "- Guessing randomly based on an equal chance of the classes\n",
    "\n",
    "\n",
    "We're going to build a class, `NaiveClassifier`, that can fit and predict based on the above approaches. We will then try it out on a few datasets and see what results we get. This should help you understand the minimal performance you should expect out of your machine learning models.\n",
    "\n",
    "The way `NaiveClassifier` should work is that we instantiate it with an `approach` and an optional `value` depending on the method.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- always predict class 1 would be: `clf = NaiveClassifier(approach=\"always\", value=1)`\n",
    "- always predict most common class would be: `clf = NaiveClassifier(approach=\"most\")`\n",
    "- predict based on class distribution: `clf = NaiveClassifier(approach=\"distribution\")`\n",
    "- predict based on equal class distribution: `clf = NaiveClassifier(approach=\"equal\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that we are *not* building a Naive Bayes Classifier\n",
    "\n",
    "A Naive Bayes Classifier is a legitimate ML model that predicts output targets based on input features. In contrast, the point of this exercise and the naive (non-Bayesian) classifier you are building is to instill awareness in you that a ML model might give *seemingly* reasonable prediction scores despite having actually learned no meaningful relationship between features and targets.\n",
    "\n",
    "Your naive classifier models only the distribution of target values, or some statistic of that distribution. It is *not* a machine learning model, because there is no learning involved. Thus, any ML that underperforms relative to such a naive classifier presumably has not actually learned any useful connection between the features and the targets.\n",
    "\n",
    "In addition, this exercise is intended to help you understand how the sci-kit learn model classes are typically constructed, by building one yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the imported packages below. These are the packages you may use for your solutions.\n",
    "\n",
    "Use the ```stat``` package to help you extract desired statistics from your target data. Use the ```random``` package to help you randomly select values for your naive classifier's prediction, in a manner that reflects the specified ```approach```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:05:37.368966Z",
     "start_time": "2020-11-15T23:05:30.237842Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7150a9a2cf9e261ee812b05e651f385f",
     "grade": false,
     "grade_id": "cell-9213e34f09e91de2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:05:44.522110Z",
     "start_time": "2020-11-15T23:05:44.519108Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc57bd92d9b18791aad8a01b8362f414",
     "grade": false,
     "grade_id": "cell-2072e6f2de42e5af",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_most_common(labels):\n",
    "    \"\"\"Select the most common value (the mode) in an iterable of labels\n",
    "    \n",
    "    Args:\n",
    "        labels (iterable): An iterable of integers representing the labels of a dataset\n",
    "    \n",
    "    Returns:\n",
    "        int: The most common element in the iterable\n",
    "    \"\"\"\n",
    "    return np.bincount(labels).argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T23:05:44.923955Z",
     "start_time": "2020-11-15T23:05:44.920953Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f10cadf9d39cca14641dae7f0c71454",
     "grade": true,
     "grade_id": "cell-8e5505cea4302a14",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert select_most_common([1,2,2,3,4,5]) == 2\n",
    "assert select_most_common([1,1,1,1,1,1,2,2,2]) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution to the function definition below will likely require some deeper thinking on your part.\n",
    "\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>Click here for a hint</summary>\n",
    "    \n",
    "There are multiple coding approaches. As a hint to one type of approach, consider how you might work with the cumulative distribution function (cdf) rather than the probability distribution function (pdf). Yet, don't let this hint constrain your thinking and creativity.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:08.480604Z",
     "start_time": "2020-11-16T03:09:08.476600Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "893789cec2524cdf451e591498ea5709",
     "grade": true,
     "grade_id": "cell-4547cb50665c9747",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict_from_distribution(distribution):\n",
    "    \"\"\"Draw a sample from a specified categorical distribution\n",
    "    \n",
    "    Args:\n",
    "        distribution (iterable): An iterable of the probabilities of each class in the distrubtion.\n",
    "                                 The distrubution probabilities must sum to 1.\n",
    "    \n",
    "    Returns:\n",
    "        int: The 0-indexed class of the drawn sample.\n",
    "    \"\"\"    \n",
    "    assert sum(distribution) == 1\n",
    "    for idx, value in enumerate(distribution):\n",
    "        if random.random() < value:\n",
    "            if idx == 0: return idx\n",
    "            if idx > 1: return idx-1\n",
    "        if idx == len(distribution)-1:\n",
    "            return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:09.089627Z",
     "start_time": "2020-11-16T03:09:09.085124Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ebc09ff2b2ab3f7a2f880ec0ceebcf1",
     "grade": false,
     "grade_id": "cell-bcf996323af296d9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 2, 0, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example predictions\n",
    "# You should see 10 results with about 5 0s, 1 1, and 4 2's.\n",
    "# You can print val in order to see if it's being calculated correctly\n",
    "[predict_from_distribution([0.5, 0.1, 0.4]) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ```fit()``` method in the class definition below you need to compute and store any variables that you will need for the ```approach``` that is specified in the ```__init__()``` method and the corresponding ```predict()``` method. The number of variables you need to store differs depending on the ```approach```.\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary>Click here for a hint</summary>\n",
    "    \n",
    "1. Try coding the predict function first and then from there determine what you would need to know ahead of time that you can learn from the fit stage.\n",
    "\n",
    "2. Update the fit method with that information storing it into the class using `self.some_stored_value`. You can then access `self.some_stored_value` in the predict stage.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:11.250622Z",
     "start_time": "2020-11-16T03:09:11.239613Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d98b468ae54931df1cb7161cde8f1e4a",
     "grade": false,
     "grade_id": "cell-317516af1385c134",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    \"\"\"A Naive Classifier that predicts classes using simple approaches.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, approach, value=None):\n",
    "        \"\"\"Initialize the NaiveClassifier\n",
    "        \n",
    "        Args:\n",
    "            approach (str): One of \"always\", \"most\", \"distribution\", \"equal\"\n",
    "            value (int, optional): Defaults to None. The value of the class to select if approach is \"always\"\n",
    "        \"\"\"\n",
    "        assert approach in [\"always\", \"most\", \"distribution\", \"equal\"]\n",
    "        self.approach = approach\n",
    "        self.value = value\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\"Fit to data and labels\n",
    "        Examples:\n",
    "            always predict class 1 would be: clf = NaiveClassifier(approach=\"always\", value=1)\n",
    "            always predict most common class would be: clf = NaiveClassifier(approach=\"most\")\n",
    "            predict based on class distribution: clf = NaiveClassifier(approach=\"distribution\")\n",
    "            predict based on equal class distribution: clf = NaiveClassifier(approach=\"equal\")\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The features of the data\n",
    "            y (iterable): The labels of the data\n",
    "        \"\"\"\n",
    "        if self.approach == (\"always\"):\n",
    "            self.value\n",
    "            \n",
    "        elif self.approach == \"most\":\n",
    "            self.value = select_most_common(y)\n",
    "\n",
    "        elif self.approach == \"distribution\":\n",
    "            unique, counts = np.unique(y, return_counts=True)\n",
    "            frequencies = np.asarray((unique, counts)).T\n",
    "            self.distribution = [frequency[1]/len(y) for frequency in frequencies]\n",
    "            \n",
    "        elif self.approach == \"equal\":\n",
    "            unique, counts = np.unique(y, return_counts=True)\n",
    "            self.distribution = [1/len(unique) for i in range(len(unique))]\n",
    "\n",
    "    def predict(self,X):\n",
    "        \"\"\"Predict the labels of a new set of datapoints\n",
    "        \n",
    "        Args:\n",
    "            X (iterable): The data to predict\n",
    "        \"\"\"\n",
    "        if self.approach == \"always\":\n",
    "            return [self.value]*len(X)\n",
    "        elif self.approach == \"most\":\n",
    "            return [self.value]*len(X)\n",
    "        elif self.approach == \"distribution\":\n",
    "            return [predict_from_distribution(self.distribution) for i in range(len(X))]\n",
    "        elif self.approach == \"equal\":\n",
    "            return [predict_from_distribution(self.distribution) for i in range(len(X))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f645ae9d69c9cf50f569db4b04b1766",
     "grade": false,
     "grade_id": "cell-a22c0b698e77fade",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Let's create a few datasets that we'll use to analyze how a predictor would work with each of those approaches. Here are all the datasets we'll create:\n",
    "\n",
    "- 2 classes (0 and 1), equally distributed\n",
    "- 2 classes with 0 at 90% and 1 at 10%\n",
    "- 3 classes (0, 1, and 2), equally distributed\n",
    "- 3 classes with 0 at 90%, 1 at 9% and 2 at 1%\n",
    "\n",
    "With these classes, you are setting them to be **exactly at the desired percentages** and not generating them randomly from a distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:11.952695Z",
     "start_time": "2020-11-16T03:09:11.945688Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ba695054ebef8b13c59d90961417a3e",
     "grade": false,
     "grade_id": "cell-41dd1414621c39ae",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# You will create the labels for each of the listed datasets (above) with length n\n",
    "# Name your listed datasets as: binary_equal, binary_unequal, trinary_equal and trinary_unequal\n",
    "# The datasets may be lists or numpy arrays.\n",
    "\n",
    "labels = [0,1,2]\n",
    "n = 15000\n",
    "features = np.zeros((n,3))\n",
    "\n",
    "binary_equal = [labels[0]]*int(n/2) + [labels[1]]*int(n/2)\n",
    "binary_unequal = [labels[0]]*int(n*0.9) + [labels[1]]*int(n*0.1)\n",
    "trinary_equal =  [labels[0]]*int(n/3) + [labels[1]]*int(n/3) + [labels[2]]*int(n/3)\n",
    "trinary_unequal =[labels[0]]*int(n*0.9) + [labels[1]]*int(n*0.09) + [labels[2]]*int(n*0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:12.325159Z",
     "start_time": "2020-11-16T03:09:12.317152Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95b318c451acafebc1ef5cf792408b8b",
     "grade": true,
     "grade_id": "cell-7458977b6dde20e7",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.all(np.bincount(binary_equal) == np.array([7500,7500]))\n",
    "assert np.all(np.bincount(binary_unequal) == np.array([13500,1500]))\n",
    "assert np.all(np.bincount(trinary_equal) == np.array([5000,5000,5000]))\n",
    "assert np.all(np.bincount(trinary_unequal) == np.array([13500,1350,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:12.752811Z",
     "start_time": "2020-11-16T03:09:12.749308Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1695b48d77fcea33800cc7d8d2fe39f0",
     "grade": false,
     "grade_id": "cell-900b0957df9f3734",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "datasets = [{\n",
    "    \"name\": \"Binary Classification Equally Distributed\",\n",
    "    \"labels\": binary_equal\n",
    "},{\n",
    "    \"name\": \"Binary Classification 90:10\",\n",
    "    \"labels\": binary_unequal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification Equally Distributed\",\n",
    "    \"labels\": trinary_equal\n",
    "},{\n",
    "    \"name\": \"3-Class Classification 90:9:1\",\n",
    "    \"labels\": trinary_unequal\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e862321ba724796066c14a3c70f4b10",
     "grade": false,
     "grade_id": "cell-c91e34d42c72031a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Testing\n",
    "\n",
    "Let's now test out our Naive Classifiers on the above datasets. We will be training and testing on the full dataset. Since the model is actually not a machine learning algorithm and this is just for educational purposes, this lack of proper cross-validation will not be an issue. We are just using this approach to learn what the naive model would have predicted even on the data it \"trained\" on.\n",
    "\n",
    "When \"training\" or \"fitting\" the model, note that since it's not actually learning anything, it doesn't matter what the features it receives are. It is just going to predict things regardless of the features of the test data. For that reason, we'll be just using a single feature for data. The models should still work fine with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:13.452082Z",
     "start_time": "2020-11-16T03:09:13.449079Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "690263b73d8e95b494e9f22791faca90",
     "grade": false,
     "grade_id": "cell-bd4beeead806b52d",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create three classifers. Classifiers that always predict 0, 1, and 2, respectively.\n",
    "# Name them always_zero, always_one and always_two respectively\n",
    "\n",
    "always_zero = NaiveClassifier(\"always\", 0)\n",
    "always_one = NaiveClassifier(\"always\", 1)\n",
    "always_two = NaiveClassifier(\"always\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:13.702539Z",
     "start_time": "2020-11-16T03:09:13.699536Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f1007b63c813551e9e24d6519493763",
     "grade": true,
     "grade_id": "cell-522eb486ae501239",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert always_zero.approach==\"always\"\n",
    "assert always_zero.value == 0\n",
    "assert always_one.approach==\"always\"\n",
    "assert always_one.value == 1\n",
    "assert always_two.approach==\"always\"\n",
    "assert always_two.value == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:13.988135Z",
     "start_time": "2020-11-16T03:09:13.985633Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca9ad85d57aa05f8982f78f82bfbb0d9",
     "grade": false,
     "grade_id": "cell-46ead0e0ddbe2d1e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts the most frequent class\n",
    "# Name it most_est\n",
    "\n",
    "most_est = NaiveClassifier(\"most\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:14.266875Z",
     "start_time": "2020-11-16T03:09:14.262872Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de2edf8b4addac9a343f0a95ba40c188",
     "grade": true,
     "grade_id": "cell-b8897d0392ce989e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert most_est.approach==\"most\"\n",
    "most_est.fit([0,0,0,0,0], [0,1,1,1,0])\n",
    "assert most_est.predict([0,0,0]) == [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:14.547115Z",
     "start_time": "2020-11-16T03:09:14.544613Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a89a20e3857151da03a35a707efaa20a",
     "grade": false,
     "grade_id": "cell-6dd3561533dc7fab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts based on the distribution of the classes\n",
    "# Name it dist_est\n",
    "\n",
    "dist_est = NaiveClassifier(\"distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:14.830859Z",
     "start_time": "2020-11-16T03:09:14.822352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016\n"
     ]
    }
   ],
   "source": [
    "## To test the predict() function, use its output to create a distribution based\n",
    "## on a large number of samples/predictions, and compare that to the original\n",
    "## distribution. The two distributions should be very close.\n",
    "\n",
    "assert dist_est.approach == \"distribution\"\n",
    "nn = 1000\n",
    "X = np.zeros((nn, 1), dtype=np.int)\n",
    "y = [0 if random.random()>0.9 else 1 for i in range(nn)]\n",
    "true_distrib = np.bincount(y)\n",
    "dist_est.fit(X, y)\n",
    "pred_distrib = np.bincount(dist_est.predict(X))\n",
    "\n",
    "# Distributions should be close, but not necessarily identical\n",
    "earth_mover_distance = np.sum(np.abs(np.subtract(true_distrib, pred_distrib))) / nn / 2\n",
    "print(earth_mover_distance)\n",
    "assert earth_mover_distance < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:15.127114Z",
     "start_time": "2020-11-16T03:09:15.124612Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd5dbac962f0f4ca653eb8e8c80057a9",
     "grade": false,
     "grade_id": "cell-b60f6f134886db8f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Create a classifer that predicts equally any of the classes\n",
    "# Name it equal_est\n",
    "\n",
    "equal_est = NaiveClassifier(\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:15.426371Z",
     "start_time": "2020-11-16T03:09:15.418363Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c4286b004cf26c5405ce0310cd11184",
     "grade": true,
     "grade_id": "cell-bcde51ec3db375fa",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n"
     ]
    }
   ],
   "source": [
    "## To test the predict() function, use its output to create a distribution based\n",
    "## on a large number of samples/predictions, and compare that to an equal (uniform)\n",
    "## distribution. The two distributions should be very close.\n",
    "\n",
    "assert equal_est.approach == \"equal\"\n",
    "nn = 1000\n",
    "X = np.zeros((nn, 1), dtype=np.int)\n",
    "y = [0 if random.random()>0.9 else 1 for i in range(nn)]\n",
    "equal_est.fit(X, y)\n",
    "pred_distrib = np.bincount(equal_est.predict(X))\n",
    "\n",
    "# Prediced distribution should be close to uniform distrubution, but not necessarily identical\n",
    "target_distrib = [nn/2, nn/2]\n",
    "earth_mover_distance = np.sum(np.abs(np.subtract(target_distrib, pred_distrib))) / nn / 2\n",
    "print(earth_mover_distance)\n",
    "assert earth_mover_distance < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:15.737138Z",
     "start_time": "2020-11-16T03:09:15.733134Z"
    }
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    {\n",
    "        \"name\": \"Always Zero\",\n",
    "        \"estimator\": always_zero\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always One\",\n",
    "        \"estimator\": always_one\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Always Two\",\n",
    "        \"estimator\": always_two\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Most Common\",\n",
    "        \"estimator\": most_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Distribution Based\",\n",
    "        \"estimator\": dist_est\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Equally\",\n",
    "        \"estimator\": equal_est\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:16.758261Z",
     "start_time": "2020-11-16T03:09:15.985097Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd1900182b5fb09f2a9e5e00a4204cf1",
     "grade": true,
     "grade_id": "cell-4fa0002da84133fb",
     "locked": false,
     "points": 70,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Binary Classification Equally Distributed\n",
      "====================================================================================================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67      7500\n",
      "           1       0.00      0.00      0.00      7500\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.25      0.50      0.33     15000\n",
      "weighted avg       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7500\n",
      "           1       0.50      1.00      0.67      7500\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.25      0.50      0.33     15000\n",
      "weighted avg       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.0 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    7500.0\n",
      "           1       0.00      0.00      0.00    7500.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00   15000.0\n",
      "   macro avg       0.00      0.00      0.00   15000.0\n",
      "weighted avg       0.00      0.00      0.00   15000.0\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      7500\n",
      "           1       0.50      1.00      0.67      7500\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.25      0.50      0.33     15000\n",
      "weighted avg       0.25      0.50      0.33     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.49493333333333334 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.10      0.17      7500\n",
      "           1       0.50      0.89      0.64      7500\n",
      "\n",
      "    accuracy                           0.49     15000\n",
      "   macro avg       0.49      0.49      0.40     15000\n",
      "weighted avg       0.49      0.49      0.40     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.4992666666666667 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50      7500\n",
      "           1       0.50      0.50      0.50      7500\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.50      0.50      0.50     15000\n",
      "weighted avg       0.50      0.50      0.50     15000\n",
      "\n",
      "====================================================================================================\n",
      "Binary Classification 90:10\n",
      "====================================================================================================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     13500\n",
      "           1       0.00      0.00      0.00      1500\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.45      0.50      0.47     15000\n",
      "weighted avg       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.1 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     13500\n",
      "           1       0.10      1.00      0.18      1500\n",
      "\n",
      "    accuracy                           0.10     15000\n",
      "   macro avg       0.05      0.50      0.09     15000\n",
      "weighted avg       0.01      0.10      0.02     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.0 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00   13500.0\n",
      "           1       0.00      0.00      0.00    1500.0\n",
      "           2       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00   15000.0\n",
      "   macro avg       0.00      0.00      0.00   15000.0\n",
      "weighted avg       0.00      0.00      0.00   15000.0\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.1 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     13500\n",
      "           1       0.10      1.00      0.18      1500\n",
      "\n",
      "    accuracy                           0.10     15000\n",
      "   macro avg       0.05      0.50      0.09     15000\n",
      "weighted avg       0.01      0.10      0.02     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.18706666666666666 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.11      0.19     13500\n",
      "           1       0.10      0.90      0.18      1500\n",
      "\n",
      "    accuracy                           0.19     15000\n",
      "   macro avg       0.51      0.51      0.19     15000\n",
      "weighted avg       0.83      0.19      0.19     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5005333333333334 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.50      0.64     13500\n",
      "           1       0.10      0.50      0.17      1500\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.50      0.50      0.40     15000\n",
      "weighted avg       0.82      0.50      0.60     15000\n",
      "\n",
      "====================================================================================================\n",
      "3-Class Classification Equally Distributed\n",
      "====================================================================================================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50      5000\n",
      "           1       0.00      0.00      0.00      5000\n",
      "           2       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.11      0.33      0.17     15000\n",
      "weighted avg       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5000\n",
      "           1       0.33      1.00      0.50      5000\n",
      "           2       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.11      0.33      0.17     15000\n",
      "weighted avg       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5000\n",
      "           1       0.00      0.00      0.00      5000\n",
      "           2       0.33      1.00      0.50      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.11      0.33      0.17     15000\n",
      "weighted avg       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.3333333333333333 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5000\n",
      "           1       0.33      1.00      0.50      5000\n",
      "           2       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.11      0.33      0.17     15000\n",
      "weighted avg       0.11      0.33      0.17     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.33286666666666664 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.16      5000\n",
      "           1       0.33      0.89      0.49      5000\n",
      "           2       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.22      0.33      0.22     15000\n",
      "weighted avg       0.22      0.33      0.22     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Produced an accuracy score of 0.3338 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.50      0.40      5000\n",
      "           1       0.33      0.50      0.40      5000\n",
      "           2       0.00      0.00      0.00      5000\n",
      "\n",
      "    accuracy                           0.33     15000\n",
      "   macro avg       0.22      0.33      0.27     15000\n",
      "weighted avg       0.22      0.33      0.27     15000\n",
      "\n",
      "====================================================================================================\n",
      "3-Class Classification 90:9:1\n",
      "====================================================================================================\n",
      "--------------------\n",
      "Estimating with Always Zero\n",
      "--------------------\n",
      "Produced an accuracy score of 0.9 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     13500\n",
      "           1       0.00      0.00      0.00      1350\n",
      "           2       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.90     15000\n",
      "   macro avg       0.30      0.33      0.32     15000\n",
      "weighted avg       0.81      0.90      0.85     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always One\n",
      "--------------------\n",
      "Produced an accuracy score of 0.09 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     13500\n",
      "           1       0.09      1.00      0.17      1350\n",
      "           2       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.09     15000\n",
      "   macro avg       0.03      0.33      0.06     15000\n",
      "weighted avg       0.01      0.09      0.01     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Always Two\n",
      "--------------------\n",
      "Produced an accuracy score of 0.01 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     13500\n",
      "           1       0.00      0.00      0.00      1350\n",
      "           2       0.01      1.00      0.02       150\n",
      "\n",
      "    accuracy                           0.01     15000\n",
      "   macro avg       0.00      0.33      0.01     15000\n",
      "weighted avg       0.00      0.01      0.00     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Most Common\n",
      "--------------------\n",
      "Produced an accuracy score of 0.09 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     13500\n",
      "           1       0.09      1.00      0.17      1350\n",
      "           2       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.09     15000\n",
      "   macro avg       0.03      0.33      0.06     15000\n",
      "weighted avg       0.01      0.09      0.01     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Distribution Based\n",
      "--------------------\n",
      "Produced an accuracy score of 0.177 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.11      0.19     13500\n",
      "           1       0.09      0.88      0.16      1350\n",
      "           2       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.18     15000\n",
      "   macro avg       0.33      0.33      0.12     15000\n",
      "weighted avg       0.81      0.18      0.19     15000\n",
      "\n",
      "--------------------\n",
      "Estimating with Equally\n",
      "--------------------\n",
      "Produced an accuracy score of 0.5021333333333333 and the following report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.51      0.65     13500\n",
      "           1       0.09      0.50      0.15      1350\n",
      "           2       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.50     15000\n",
      "   macro avg       0.33      0.34      0.27     15000\n",
      "weighted avg       0.82      0.50      0.60     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each dataset, apply each estimator to generate predictions and save them as pred\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "for dataset in datasets:\n",
    "    name = dataset[\"name\"]\n",
    "    labels = dataset[\"labels\"]\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{name}\")\n",
    "    print(\"=\"*100)\n",
    "    for est in estimators:\n",
    "        estimator_name = est[\"name\"]\n",
    "        print(\"-\"*20)\n",
    "        print(f\"Estimating with {estimator_name}\")\n",
    "        print(\"-\"*20)\n",
    "        pred = est[\"estimator\"].predict(labels)\n",
    "    \n",
    "        print(f\"Produced an accuracy score of {accuracy_score(labels, pred)} and the following report\")\n",
    "        print(classification_report(labels, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:16.873359Z",
     "start_time": "2020-11-16T03:09:16.869857Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45628ea31d01b86cd64bd71ec22dfecf",
     "grade": true,
     "grade_id": "cell-9b05ea606e1c0cd8",
     "locked": false,
     "points": 80,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The NaiveClassifier is a classifier that uses the most basic of guessing approaches\n",
      "since it's not actually learning anything. It is just going to predict things regardless \n",
      "of the features of the test data. The aproach, 'always', always guess the same number. \n",
      "This doesn't include any logic that takes into consideration the distribution make \n",
      "this method as good as make 'A' as the answer to every multiple choice question. When \n",
      "looking at the Equally Distributed dataset, this method will correctly guess N of the \n",
      "labels where N=labels/num_class. This method will when the dataset has a different \n",
      "distribution will depend largely on the chosen class since the accuracy will be whichever \n",
      "distribution that label represents. Again since nothing is learned about the fit data, choosing\n",
      "the value to initialize the model with is largely random and directly correlated to the \n",
      "accuracy. When we look at the \"most\" model, this tries to 'learn' basic information about the \n",
      "fit dataset to evaluate the test dataset. By choosing the value that appeared most in the\n",
      "train set, the model is trying to mimic the previously opitmal result that one could achieve \n",
      "by only guessing one number for every label. The results on the test set were not great though as \n",
      "the test set was mostly composed of the other labels, making this relatively okay on the train\n",
      "set, but horribly on the test set (Poor generalization). The distributed model's performance\n",
      "was in the middle of all the models meaning that it might generalize to unknown data the best\n",
      "out of all the methods. This model tried to 'learn' the distribution of the train set to mimic\n",
      "the results on the test set. The equally distributed approach is naive just like the \"always\" \n",
      "approach, but would be like guessing 'A', 'B', or 'C' equally. The method's accuracy scored \n",
      "about half of the labels correctly on all datasets on this run. When the dataset distribution was\n",
      "optimal for the 'always' approach, this method scored best, but otherwise, this equally distributed\n",
      "method provided midway results above the \"distributed\" approach that was fit to the train sets.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Please describe your conclusions based on the above results\n",
    "# You must write at least 300 characters\n",
    "# This portion is worth 100 points (20% of the CS)\n",
    "# Save your answer to conclusions\n",
    "conclusions = f'''\n",
    "The NaiveClassifier is a classifier that uses the most basic of guessing approaches\n",
    "since it's not actually learning anything. It is just going to predict things regardless \n",
    "of the features of the test data. The aproach, 'always', always guess the same number. \n",
    "This doesn't include any logic that takes into consideration the distribution make \n",
    "this method as good as make 'A' as the answer to every multiple choice question. When \n",
    "looking at the Equally Distributed dataset, this method will correctly guess N of the \n",
    "labels where N=labels/num_class. This method will when the dataset has a different \n",
    "distribution will depend largely on the chosen class since the accuracy will be whichever \n",
    "distribution that label represents. Again since nothing is learned about the fit data, choosing\n",
    "the value to initialize the model with is largely random and directly correlated to the \n",
    "accuracy. When we look at the \"most\" model, this tries to 'learn' basic information about the \n",
    "fit dataset to evaluate the test dataset. By choosing the value that appeared most in the\n",
    "train set, the model is trying to mimic the previously opitmal result that one could achieve \n",
    "by only guessing one number for every label. The results on the test set were not great though as \n",
    "the test set was mostly composed of the other labels, making this relatively okay on the train\n",
    "set, but horribly on the test set (Poor generalization). The distributed model's performance\n",
    "was in the middle of all the models meaning that it might generalize to unknown data the best\n",
    "out of all the methods. This model tried to 'learn' the distribution of the train set to mimic\n",
    "the results on the test set. The equally distributed approach is naive just like the \"always\" \n",
    "approach, but would be like guessing 'A', 'B', or 'C' equally. The method's accuracy scored \n",
    "about half of the labels correctly on all datasets on this run. When the dataset distribution was\n",
    "optimal for the 'always' approach, this method scored best, but otherwise, this equally distributed\n",
    "method provided midway results above the \"distributed\" approach that was fit to the train sets.\n",
    "'''\n",
    "print(conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:24.070820Z",
     "start_time": "2020-11-16T03:09:24.068318Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f96902f6df775132e627f13cb16c2783",
     "grade": true,
     "grade_id": "cell-355d52c0428b75f3",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(conclusions) > 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35c02446ada971330235203f8d3b177f",
     "grade": false,
     "grade_id": "cell-d45e75d8071c765c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T03:09:25.058771Z",
     "start_time": "2020-11-16T03:09:25.055268Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc89e0660ccb53529a249ada6cc1a0cd",
     "grade": false,
     "grade_id": "cell-fb93624c53422815",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This assignment was not difficult except for the lack of direction. If better directions were provided, much confusion over what was supposed to be done would be solved. Piazza was helpful, so maybe include some of that in the directions next time.'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    return \"This assignment was not difficult except for the lack of direction. If better directions were provided, much confusion over what was supposed to be done would be solved. Piazza was helpful, so maybe include some of that in the directions next time.\"\n",
    "\n",
    "feedback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51c4d2a5734ab18322474a6f62fb5382",
     "grade": true,
     "grade_id": "cell-10ee4b2b9ba4be3d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
