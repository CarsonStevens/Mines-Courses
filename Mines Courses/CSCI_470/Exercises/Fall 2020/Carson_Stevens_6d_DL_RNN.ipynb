{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSCI 470 Activities and Case Studies\n",
    "\n",
    "1. For all activities, you are allowed to collaborate with a partner. \n",
    "1. For case studies, you should work individually and are **not** allowed to collaborate.\n",
    "\n",
    "By filling out this notebook and submitting it, you acknowledge that you are aware of the above policies and are agreeing to comply with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some considerations with regard to how these notebooks will be graded:\n",
    "\n",
    "1. You can add more notebook cells or edit existing notebook cells other than \"# YOUR CODE HERE\" to test out or debug your code. We actually highly recommend you do so to gain a better understanding of what is happening. However, during grading, **these changes are ignored**. \n",
    "2. You must ensure that all your code for the particular task is available in the cells that say \"# YOUR CODE HERE\"\n",
    "3. Every cell that says \"# YOUR CODE HERE\" is followed by a \"raise NotImplementedError\". You need to remove that line. During grading, if an error occurs then you will not receive points for your work in that section.\n",
    "4. If your code passes the \"assert\" statements, then no output will result. If your code fails the \"assert\" statements, you will get an \"AssertionError\". Getting an assertion error means you will not receive points for that particular task.\n",
    "5. If you edit the \"assert\" statements to make your code pass, they will still fail when they are graded since the \"assert\" statements will revert to the original. Make sure you don't edit the assert statements.\n",
    "6. We may sometimes have \"hidden\" tests for grading. This means that passing the visible \"assert\" statements is not sufficient. The \"assert\" statements are there as a guide but you need to make sure you understand what you're required to do and ensure that you are doing it correctly. Passing the visible tests is necessary but not sufficient to get the grade for that cell.\n",
    "7. When you are asked to define a function, make sure you **don't** use any variables outside of the parameters passed to the function. You can think of the parameters being passed to the function as a hint. Make sure you're using all of those variables.\n",
    "8. Finally, **make sure you run \"Kernel > Restart and Run All\"** and pass all the asserts before submitting. If you don't restart the kernel, there may be some code that you ran and deleted that is still being used and that was why your asserts were passing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "148a186cdc339d18c6a3c0bf33ad5a6e",
     "grade": false,
     "grade_id": "cell-d07e9bbbd9efabf6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Deep Learning - Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:40.348340Z",
     "start_time": "2020-11-07T21:46:11.773324Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df48be318c20412564ef812c320d2510",
     "grade": false,
     "grade_id": "cell-aaad388f467a51c0",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.layers import SimpleRNN, GRU, LSTM, Embedding, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7317042415be1e532b31c2cc056d9fa",
     "grade": false,
     "grade_id": "cell-bda9bc8e1d0c997d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will be using the IMDB dataset outlined in the keras documentation [here](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification). We will be applying a supervised learning application to text where we predict the sentiment of the IMDB reviews.\n",
    "\n",
    "Take a look at the imports above. For the RNN based imports see the [RNN documentation](https://keras.io/layers/recurrent). For preprocessing using `sequence` see the [sequence documentation](https://keras.io/preprocessing/sequence). For Embedding, see the [Embedding documentation](https://keras.io/layers/embeddings/).\n",
    "\n",
    "From the Keras documentation, linked above:\n",
    ">\"This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:45.645069Z",
     "start_time": "2020-11-07T21:46:40.357349Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "257838f74061ae830d9d6f55eabd08ed",
     "grade": false,
     "grade_id": "cell-c5683134993794d6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carson\\Anaconda3\\envs\\NN\\lib\\site-packages\\tensorflow_core\\python\\keras\\datasets\\imdb.py:129: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\Carson\\Anaconda3\\envs\\NN\\lib\\site-packages\\tensorflow_core\\python\\keras\\datasets\\imdb.py:130: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "maxlen = 100 # Only use sentences up to this many words\n",
    "n = 20000 # Only use the most frequent n words\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:45.663085Z",
     "start_time": "2020-11-07T21:46:45.653576Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7c4a5c23bee6c65b41a116d5dcaf6c7",
     "grade": false,
     "grade_id": "cell-2d04aa072205ee4a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:45.746156Z",
     "start_time": "2020-11-07T21:46:45.670092Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4c3388aacf1d735a644960c64697ef8",
     "grade": false,
     "grade_id": "cell-c69f7bd45588c10f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:45.831730Z",
     "start_time": "2020-11-07T21:46:45.752662Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b123c8981fb62ef850e3f8921796d5c0",
     "grade": false,
     "grade_id": "cell-59607cac09a99a93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element 0 has a length of 218\n",
      "Element 1 has a length of 189\n",
      "Element 2 has a length of 141\n",
      "Element 3 has a length of 550\n",
      "Element 4 has a length of 147\n",
      "Element 5 has a length of 43\n",
      "Element 6 has a length of 123\n",
      "Element 7 has a length of 562\n",
      "Element 8 has a length of 233\n",
      "Element 9 has a length of 130\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Element {i} has a length of {len(x_train[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:46.037907Z",
     "start_time": "2020-11-07T21:46:45.838235Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25138d378e0de2c56acc6fc7c8a80cce",
     "grade": false,
     "grade_id": "cell-9d17ff409cf0ed6a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:46.798562Z",
     "start_time": "2020-11-07T21:46:46.044413Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f01af8b921e7219a1d6496f80022e99e",
     "grade": false,
     "grade_id": "cell-29008f854c9ed905",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:46.824585Z",
     "start_time": "2020-11-07T21:46:46.820582Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce4ea6cd24d56fdd9e3646d504c1638b",
     "grade": false,
     "grade_id": "cell-26b3b6b877561751",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 100), (25000, 100))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb0658983557cfc6d5d749c18d5c3a08",
     "grade": false,
     "grade_id": "cell-80d546e03cc3a91a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Each data sample is a sequence of integers that represent the index of the word in our vocabulary. This saves on storage when compared to a vector that's as long as our vocabulary with all 0's and just one 1 as discussed in the lecture. We will be using the [Embedding layer](https://keras.io/layers/embeddings/) to adapt this for our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T21:46:46.954196Z",
     "start_time": "2020-11-07T21:46:46.860115Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2793d772ae01513635a946f32a65d908",
     "grade": false,
     "grade_id": "cell-9c1b0c9c7d26e3fc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All values of the targets are integers with the following max and min values\n",
      "1, 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"All values of the targets are integers with the following max and min values\")\n",
    "print(f\"{y_train.max()}, {y_train.min()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0346e2170feadaf176a0c0d32ccb8513",
     "grade": false,
     "grade_id": "cell-a96be599550f72f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We will build three networks, using basic RNNs, GRUs and LSTMs. We will then compare their performance in predicting the classes of reviews appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:19:07.046295Z",
     "start_time": "2020-11-07T22:19:05.463933Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e1a8a9f06ee330c7df4d7882b5d8130",
     "grade": false,
     "grade_id": "cell-89247ca5db4b603e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Define \"simple_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
    "# saved as \"my_simple\".\n",
    "# \n",
    "# Here you will create a simple RNN using one SimpleRNN layer with dropout and recurrent_dropout\n",
    "# (see argument options in SimpleRNN documentation).\n",
    "# \n",
    "# You will need to use an Embedding layer as the first layer (to convert the data appropriately)\n",
    "# followed by the SimpleRNN layer. Select an embedding size of your choice, and use that for your\n",
    "# SimpleRNN layer's output dimensions as well.\n",
    "#\n",
    "# Finally, create an output layer that applies to our dataset task of binary classification\n",
    "\n",
    "simple_layers = [Embedding(input_dim=n, output_dim=int(n*0.05),input_length=maxlen),\n",
    "                 SimpleRNN(int(n*0.05), dropout=0.05, recurrent_dropout=0.05),\n",
    "                 Dense(1, activation=\"relu\")]\n",
    "\n",
    "my_simple = Sequential(simple_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:20:32.781386Z",
     "start_time": "2020-11-07T22:20:32.776882Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a8cf4a1554786648cfb1318f2bc79dc",
     "grade": true,
     "grade_id": "cell-a693cb84784a5e8d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(simple_layers) == 3\n",
    "assert isinstance(simple_layers[0], Embedding)\n",
    "assert isinstance(simple_layers[1], SimpleRNN)\n",
    "assert isinstance(simple_layers[2], Dense)\n",
    "assert simple_layers[0].output_dim == simple_layers[1].units\n",
    "assert simple_layers[1].dropout > 0\n",
    "assert simple_layers[1].recurrent_dropout > 0\n",
    "assert my_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:25:45.147714Z",
     "start_time": "2020-11-07T22:20:33.655640Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d73657260a770b1f13296effcaa37d9",
     "grade": false,
     "grade_id": "cell-10a0d33cc462aa67",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "25000/25000 [==============================] - 311s 12ms/sample - loss: 7.5601 - accuracy: 0.5066\n",
      "Wall time: 5min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17bee9a9f60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "my_simple.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "my_simple.fit(x_train, y_train, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:28:52.220944Z",
     "start_time": "2020-11-07T22:28:51.910678Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a588817120cfc85fdc1281fdb99a05ee",
     "grade": false,
     "grade_id": "cell-9b7b7778053b0aa3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Define \"gru_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
    "# saved as \"my_gru\".\n",
    "#\n",
    "# Here you will create an RNN using a GRU layer, with dropout and recurrent_dropout.\n",
    "#\n",
    "# Use an input Embedding layer and output Dense layer, as in the simple RNN model.\n",
    "\n",
    "gru_layers = [Embedding(input_dim=n, output_dim=int(n*0.01),input_length=maxlen),\n",
    "                 GRU(int(n*0.01), dropout=0.15, recurrent_dropout=0.2),\n",
    "                 Dense(1, activation=\"relu\")]\n",
    "\n",
    "my_gru = Sequential(gru_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:28:54.164116Z",
     "start_time": "2020-11-07T22:28:54.159613Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f9a717049b8744e9490f324fba1fc24",
     "grade": true,
     "grade_id": "cell-c69132493de5ac88",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(gru_layers) == 3\n",
    "assert isinstance(gru_layers[0], Embedding)\n",
    "assert isinstance(gru_layers[1], GRU)\n",
    "assert isinstance(gru_layers[2], Dense)\n",
    "assert gru_layers[0].output_dim == gru_layers[1].units\n",
    "assert gru_layers[1].dropout > 0\n",
    "assert gru_layers[1].recurrent_dropout > 0\n",
    "assert my_gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:31:33.589321Z",
     "start_time": "2020-11-07T22:28:54.998834Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f8a2793b9cf15063bcafef69ea11131",
     "grade": false,
     "grade_id": "cell-5c71db6dcb81eb2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "25000/25000 [==============================] - 159s 6ms/sample - loss: 0.7367 - accuracy: 0.6943\n",
      "Wall time: 2min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17bf2eb1320>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "my_gru.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "my_gru.fit(x_train, y_train, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:46:14.292193Z",
     "start_time": "2020-11-07T22:46:14.023461Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "074f031adaafa55dbb69945cc42d9e40",
     "grade": false,
     "grade_id": "cell-798617aedf043516",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Define \"lstm_layers\", a list of Keras layers, that you will then use to create a Sequential model\n",
    "# saved as \"my_lstm\".\n",
    "#\n",
    "# Here you will create an RNN using an LSTM layer, again, with dropout and recurrent_dropout.\n",
    "#\n",
    "# Use an input Embedding layer and output Dense layer, as in the simple RNN and the GRU model.\n",
    "\n",
    "lstm_layers = [Embedding(input_dim=n, output_dim=int(n*0.001),input_length=maxlen),\n",
    "                 LSTM(int(n*0.001), dropout=0.05, recurrent_dropout=0.1),\n",
    "                 Dense(1, activation=\"relu\")]\n",
    "\n",
    "my_lstm = Sequential(lstm_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:46:15.151053Z",
     "start_time": "2020-11-07T22:46:15.146550Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a0e568fe8c02d9e8ae681db979b4886",
     "grade": true,
     "grade_id": "cell-58a52ce9bceabdee",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(lstm_layers) == 3\n",
    "assert isinstance(lstm_layers[0], Embedding)\n",
    "assert isinstance(lstm_layers[1], LSTM)\n",
    "assert isinstance(lstm_layers[2], Dense)\n",
    "assert lstm_layers[0].output_dim == lstm_layers[1].units\n",
    "assert lstm_layers[1].dropout > 0\n",
    "assert lstm_layers[1].recurrent_dropout > 0\n",
    "assert my_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:48:24.086518Z",
     "start_time": "2020-11-07T22:46:15.883183Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64f5b9ef67549c3ccdd52cf22907a0ed",
     "grade": false,
     "grade_id": "cell-33238b0da6c68f44",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "25000/25000 [==============================] - 128s 5ms/sample - loss: 0.7019 - accuracy: 0.6210\n",
      "Wall time: 2min 8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17d000e9fd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "my_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "my_lstm.fit(x_train, y_train, batch_size=32, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:49:25.531398Z",
     "start_time": "2020-11-07T22:48:52.563527Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06da7d2df6c07981e56afc9151b0f5ad",
     "grade": false,
     "grade_id": "cell-43b2247e569276bc",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 21s 843us/sample - loss: 7.5944 - accuracy: 0.5044\n",
      "25000/25000 [==============================] - 6s 254us/sample - loss: 0.5290 - accuracy: 0.7524\n",
      "25000/25000 [==============================] - 5s 217us/sample - loss: 0.4880 - accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your models on the test set and save the loss and accuracies to the appropriate variables:\n",
    "# model_name_loss, model_name_acc (e.g., my_simple_loss and my_simple_acc).\n",
    "\n",
    "my_simple_loss, my_simple_acc = my_simple.evaluate(x=x_test,y=y_test,batch_size=128)\n",
    "my_gru_loss, my_gru_acc = my_gru.evaluate(x=x_test,y=y_test,batch_size=128)\n",
    "my_lstm_loss, my_lstm_acc = my_lstm.evaluate(x=x_test,y=y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:49:25.553418Z",
     "start_time": "2020-11-07T22:49:25.550416Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0a15ab1242ee6a422212cdf05c096d1",
     "grade": false,
     "grade_id": "cell-24347394026d518c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your simple model achieved an accuracy of 0.5.\n",
      "Your GRU model achieved an accuracy of 0.75.\n",
      "Your LSTM model achieved an accuracy of 0.78.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your simple model achieved an accuracy of {my_simple_acc:.2}.\")\n",
    "print(f\"Your GRU model achieved an accuracy of {my_gru_acc:.2}.\")\n",
    "print(f\"Your LSTM model achieved an accuracy of {my_lstm_acc:.2}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3426ed141c7ecdfcb8765e570940a3de",
     "grade": false,
     "grade_id": "cell-95c1830b360ac2b2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Note that we are only running these models with 1 layer and training them for only 1 epoch. We can easily achieve better results by stacking multiple layers but the model would take a much longer time to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:49:25.677525Z",
     "start_time": "2020-11-07T22:49:25.569432Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d09aaaa2e38735c05865905d77323d90",
     "grade": true,
     "grade_id": "cell-3e1e2805ce275b4c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert my_simple_acc > 0.4\n",
    "assert my_gru_acc > 0.6\n",
    "assert my_lstm_acc > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "830573f46459d11e5238532d8759463e",
     "grade": false,
     "grade_id": "cell-bc503c7f94e3b8bf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T22:49:25.789121Z",
     "start_time": "2020-11-07T22:49:25.690537Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It would have been nice to have a little guidance on how to choose the amount of neurons per layer. It seems like it really effects train time, but my models seemed to platue, so it ended up being a lot of trial and error which doesn't seem right.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    return \"It would have been nice to have a little guidance on how to choose the amount of neurons per layer. It seems like it really effects train time, but my models seemed to platue, so it ended up being a lot of trial and error which doesn't seem right.\"\n",
    "\n",
    "feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f39f6185a54850c2f1f9b5b2a17b7543",
     "grade": true,
     "grade_id": "feedback-tests",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
