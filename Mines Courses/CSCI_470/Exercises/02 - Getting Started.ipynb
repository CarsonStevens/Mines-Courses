{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f05804f9115e66d8456f41b865e2439f",
     "grade": false,
     "grade_id": "cell-645350f534fce944",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "Usually, getting your environment set up is one of the most time consuming and frustrating parts of development. If you are seeing this running locally on your computer, congratulations!! You're past most of the hardship.\n",
    "\n",
    "During class, we'll be using [colab](https://g.co/colab) for our exercises but I urge you to [install Python](https://www.python.org/getit/) on your computers, [pipenv](https://docs.pipenv.org/) and set up [Jupyter](http://jupyter.org/). If you need help with this, please email me or come to office hours. \n",
    "\n",
    "In this exercise we're going to briefly go over Jupyter Notebooks, Markdown, Python, data visualization code and the machine learning workflow. There's a lot to cover so let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0813c281abb5fabcdfee326d43ef5cfe",
     "grade": false,
     "grade_id": "cell-9064f723f44e0ce5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Jupyter\n",
    "\n",
    "Right now, you're looking at a Jupyter notebook. Jupyter notebooks allow you to interactively run code while maintaining variables' states in memory. Notebooks are extremely useful for getting your ideas tested and quickly iterating on code. Once you've verified and validated your ideas, you should place any function definitions and workflow procedures in `.py` files. \n",
    "\n",
    "Notebooks have multiple cells, each cell has a code type and contents as well as output or display. This cell you're looking at is a Markdown cell. You can double click it to see (and edit) its contents. \n",
    "\n",
    "If you haven't used Markdown before, this [cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) is very useful. A portion of its contents are copied in the next cell for you to edit and experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "03d221be256ac28da91e43d2103d7e16",
     "grade": false,
     "grade_id": "cell-e9501831c6e5e2f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Markdown Cheat Sheet\n",
    "\n",
    "**If you already know markdown, you can skip this whole cell.**\n",
    "\n",
    "<-- Cheatsheet contents -->\n",
    "\n",
    "### Headings\n",
    "\n",
    "# H1\n",
    "## H2\n",
    "### H3\n",
    "#### H4\n",
    "##### H5\n",
    "###### H6\n",
    "\n",
    "Alternatively, for H1 and H2, an underline-ish style:\n",
    "\n",
    "Alt-H1\n",
    "======\n",
    "\n",
    "Alt-H2\n",
    "------\n",
    "\n",
    "### Emphasis\n",
    "\n",
    "Emphasis, aka italics, with *asterisks* or _underscores_.\n",
    "\n",
    "Strong emphasis, aka bold, with **asterisks** or __underscores__.\n",
    "\n",
    "Combined emphasis with **asterisks and _underscores_**.\n",
    "\n",
    "Strikethrough uses two tildes. ~~Scratch this.~~\n",
    "\n",
    "### Lists\n",
    "\n",
    "1. First ordered list item\n",
    "2. Another item\n",
    "⋅⋅* Unordered sub-list. \n",
    "1. Actual numbers don't matter, just that it's a number\n",
    "⋅⋅1. Ordered sub-list\n",
    "4. And another item.\n",
    "\n",
    "⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).\n",
    "\n",
    "⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅\n",
    "⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅\n",
    "⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n",
    "\n",
    "* Unordered list can use asterisks\n",
    "- Or minuses\n",
    "+ Or pluses\n",
    "\n",
    "### Links\n",
    "\n",
    "\n",
    "[I'm an inline-style link](https://www.google.com)\n",
    "\n",
    "[I'm an inline-style link with title](https://www.google.com \"Google's Homepage\")\n",
    "\n",
    "\n",
    "### Images\n",
    "\n",
    "Here's a logo (hover to see the title text):\n",
    "\n",
    "Inline-style: \n",
    "![alt text](https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png \"Logo Title Text 1\")\n",
    "\n",
    "Reference-style: \n",
    "![alt text][logo]\n",
    "\n",
    "\n",
    "### Code\n",
    "\n",
    "Inline `code` has `back-ticks around` it.\n",
    "\n",
    "```javascript\n",
    "var s = \"JavaScript syntax highlighting\";\n",
    "alert(s);\n",
    "```\n",
    " \n",
    "```python\n",
    "s = \"Python syntax highlighting\"\n",
    "print s\n",
    "```\n",
    " \n",
    "```\n",
    "No language indicated, so no syntax highlighting. \n",
    "But let's throw in a <b>tag</b>.\n",
    "```\n",
    "\n",
    "### Tables\n",
    "\n",
    "Colons can be used to align columns.\n",
    "\n",
    "| Tables        | Are           | Cool  |\n",
    "|---------------|---------------|-------|\n",
    "|1|2|3|\n",
    "|4|5|6|\n",
    "|7|8|9|\n",
    "\n",
    "There must be at least 3 dashes separating each header cell.\n",
    "The outer pipes (|) are optional, and you don't need to make the \n",
    "raw Markdown line up prettily.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1be0ae030cae9c756d6465d7ce5b4fee",
     "grade": false,
     "grade_id": "cell-cb691ef19cdf03a0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Jupyter organizes content in cells. Each cell has a type such as Code or Markdown and can be run to produce an output or render itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1026c5b8e05e0cc557a35bfb9bfb7414",
     "grade": false,
     "grade_id": "cell-c0f8dd911df4c13f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Jupyter also has some cool features that allow us to apply commands to a cell. These are called [magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html). \n",
    "\n",
    "We use magic commands by typing `%` for line magic and `%%` for cell magic. Let's try the `%%time` magic command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "72b690b7163fdf11f1fa5ebf5e501afc",
     "grade": false,
     "grade_id": "cell-8caa0572fce46f89",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "738b5697a1f519634e87d086f3b46fad",
     "grade": false,
     "grade_id": "cell-c01f50d178658d4f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "time.sleep(10) # sleep for 10 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6580ec1fa6425eb187cd7cebe312e379",
     "grade": false,
     "grade_id": "cell-6a650f80317199f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Python\n",
    "\n",
    "Let's go over some basic Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bfc794ac1aeeb56138ec2bd9f3c279a3",
     "grade": false,
     "grade_id": "cell-cc6ce1816036c77d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can do some basic maths as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "50e0b7bd0ca72b40b5cd67de093d0a41",
     "grade": false,
     "grade_id": "cell-6553d55b9c26f4bd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d27904bd75f9611a78ab7bf844cf193f",
     "grade": false,
     "grade_id": "cell-9d633c404341a65b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x = 5\n",
    "y = 2\n",
    "x + y, x / y, x // y, x **y, x % y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ba9578b8cf05963ba73cba3d39a50af",
     "grade": false,
     "grade_id": "cell-7a18eb3cd1e61cf7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can also do some simple logic flow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3627b91b67c3fc1f468708db96d86b78",
     "grade": false,
     "grade_id": "cell-3e16c14f956f2b1a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "score = 95\n",
    "if score > 90:\n",
    "    letterGrade = \"A\"\n",
    "elif score > 80:\n",
    "    letterGrade = \"B\"\n",
    "elif score > 70:\n",
    "    letterGrade = \"C\"\n",
    "else:\n",
    "    letterGrade = \"F\"\n",
    "\n",
    "print(f\"That score gets a letter grade of {letterGrade}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "02236b673138155f29c3c543c71052f8",
     "grade": false,
     "grade_id": "cell-f9312f401649e3a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This is how we iterate in a loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e451d8cea0603b1f761b997b3a2bc69",
     "grade": false,
     "grade_id": "cell-e59fb2bb46809352",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    if i == 1:\n",
    "        print(\"This is the 1st time.\")\n",
    "    elif i == 2:\n",
    "        print(\"This is the 2nd time.\")\n",
    "    elif i == 3:\n",
    "        print(\"This is the 3rd time\")\n",
    "    else:\n",
    "        print(f\"This is the {i}th time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a9e91303bcd5aa91278f9084e891bb5",
     "grade": false,
     "grade_id": "cell-bb1dc327485927f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "List comprehensions are a very powerful and useful tool in Python, here are a couple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a2f999b1578fb21751d619d5c93b02ac",
     "grade": false,
     "grade_id": "cell-d0ae3cbd43754620",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "[i+1 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7456bc574f132ce1de32b4ce66926fb8",
     "grade": false,
     "grade_id": "cell-11a0aab9a83df63c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "[i**2 for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19b57c958c561b92cbf8826c51b73acc",
     "grade": false,
     "grade_id": "cell-a1d7d137a1ea28cd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can also define some functions in Python. Here's an example function that gets the square root of sum of the squares in a list. Does this sound familiar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "96310a4141c1cedcf980144b00818af6",
     "grade": false,
     "grade_id": "cell-a0bd8f6fc1cc93f7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_metric(vector):\n",
    "    \"\"\"Get the square root of the sum of the squares in an iterable.\n",
    "\n",
    "    Args:\n",
    "        vector (iterable): the data to calculate the metric of\n",
    "    \n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    return sum([i ** 2 for i in vector])**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "964a68bc33150402f933dc5b2f35ef7b",
     "grade": false,
     "grade_id": "cell-3b6b1a25c20f29d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "get_metric([3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1bd05d656a457be78e1546bbf846be2",
     "grade": false,
     "grade_id": "cell-fe0f215cfa29f3c7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "That metric was the $\\ell_2$-norm. Can you write a function that takes a vector and value for p and determines the $\\ell_p$-norm of a vector? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5d44df27a9a44f7f8b1631e5ff6717b",
     "grade": false,
     "grade_id": "get_lp",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_lp(vector, p):\n",
    "    \"\"\"Get the $\\ell_p$-norm of data\n",
    "\n",
    "    Args:\n",
    "        vector (iterable): the data to calculate the metric of\n",
    "        p (integer): the value of p in the $\\\n",
    "    \n",
    "    Returns:\n",
    "        float\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a29219e00941cdbdd18501c174a0a776",
     "grade": false,
     "grade_id": "cell-ba4c86eda6c7d625",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "abdf7fdd046ecf2b52dde726d72b3ee9",
     "grade": true,
     "grade_id": "test_get_lp",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert get_lp([3,4],2) == 5\n",
    "assert get_lp([3,4,5],2) == pytest.approx(7,0.1)\n",
    "assert get_lp([10], 5) == pytest.approx(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3809b0083feea5f1a46be59970a91992",
     "grade": false,
     "grade_id": "cell-80342215c1ce3b68",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can also write functions in shorthand using `lambda` this creates an anonymous function. This is useful when we're using maps and filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d27caab9a21684d84addbec70e332307",
     "grade": false,
     "grade_id": "cell-5e0a0882e00433f7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lambda x : x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6de31d40f702b0ac70f4d379f21d514",
     "grade": false,
     "grade_id": "cell-a098a85eb68708fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "example_map = map(lambda x: x**3,[1,2,3,4,5])\n",
    "list(example_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e4ffbe96386e9d67b7671b5ace1a16c9",
     "grade": false,
     "grade_id": "cell-c73baa850c834cf3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "example_filter = filter(lambda x: x%2 == 1, [1,2,3,4,5])\n",
    "list(example_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57493eeac208c2e65e52b7060fe4da41",
     "grade": false,
     "grade_id": "cell-77e9acd480be4bfa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Python has a great ecosystem of libraries available and we will be using them for almost all the code we write. Here's how to import code in Python. I recommend reading up on the intricacies of imports. [1](https://stackoverflow.com/a/710603) [2](https://stackoverflow.com/a/19185936)\n",
    "\n",
    "You're probably going to see the below imports and couple lines of code very frequently at the top of most files we write. First we import the libraries we often use; [numpy](https://www.numpy.org/), [pandas](https://pandas.pydata.org/), [matplotlib](https://matplotlib.org/), and [scikit-learn](https://scikit-learn.org/). The last two lines are for setting plots to show in the notebook directly and not open up in another window and to select the styleguide for the plots we make to ggplot. You can select another style from the [available options](https://matplotlib.org/gallery/style_sheets/style_sheets_reference.html) if you like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a447c64f80515703c31b51a2cc62fdcd",
     "grade": false,
     "grade_id": "cell-c0b7f22ce2b50a72",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b929d913dee3489b6955e4340c80e5ec",
     "grade": false,
     "grade_id": "cell-da0ae52b649853c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "Let's go over some data visualization basics. To start, we'll need some data. We'll create data from a function with some noise and see if we can fit a polynomial to it. Parts of the following are extracted from the following sklearn tutorials. [1](http://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html) [2](http://scikit-learn.org/stable/auto_examples/model_selection/plot_validation_curve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1f4e3639b71e1bd334df6dd745449d0e",
     "grade": false,
     "grade_id": "cell-0f8c3a50b70fb467",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def underlying_pattern(X, noise=0.1):\n",
    "    \"\"\"Create a function to fit\n",
    "    \n",
    "    Args:\n",
    "        X numpy.array : array of x values\n",
    "        \n",
    "    Returns:\n",
    "        numpy.array : array of output values\n",
    "    \"\"\"\n",
    "    return np.cos(1.5 * np.pi * X) + np.random.randn(X.shape[0]) * noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e84ed58873fc9a3c248157a0b161234b",
     "grade": false,
     "grade_id": "cell-d6dc35df488ee449",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You should always set a seed value so that you get reproducable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b90dc9ca99be485bf7986a719dfe688",
     "grade": false,
     "grade_id": "cell-762249e498c324d6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c806acce87933a4cd44cfede6bf82a1e",
     "grade": false,
     "grade_id": "cell-e166fb21accbb415",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n = 20\n",
    "X = np.sort(np.random.rand(n))\n",
    "y = underlying_pattern(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53c1dff2f2edb60415dbd0d379be60cf",
     "grade": false,
     "grade_id": "cell-582574238b36c9b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y, marker=\"o\", linestyle=\"None\")\n",
    "# plt.scatter(X, y) # This might be easier to remember, both functions accomplish the same thing. Try switching to the commented one.\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Sample Data\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "201f427cef0a13393114c0aba49f7ff8",
     "grade": false,
     "grade_id": "cell-7c0b2325851d9f90",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Machine Learning Workflow\n",
    "\n",
    "Now that we have some data, let's try to fit a machine learning model, the one we already covered, polynomial regression, to the data. For now, you'll get all the code you need to run this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "89046734d89a9da1128499652b4b3485",
     "grade": false,
     "grade_id": "cell-42a470070c6016a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5cdd33bcbd3e648a6c62f0c6f3d91e38",
     "grade": false,
     "grade_id": "cell-87c0fdb1dec63419",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "X_model, X_valid, y_model, y_valid = train_test_split(X_train, y_train, random_state=0, test_size=0.2)\n",
    "\n",
    "print(f\"All Data:        {len(X)} points\")\n",
    "print(f\"Training data:   {len(X_train)} points\")\n",
    "print(f\"Testing data:    {len(X_test)} points\")\n",
    "print(f\"Modeling data:   {len(X_model)} points\")\n",
    "print(f\"Validation data: {len(X_valid)} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20828ef920e73852ae0f7d8cf75ea4a7",
     "grade": false,
     "grade_id": "cell-5f32f5d556fff0a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X_model, y_model, marker=\"o\", linestyle=\"None\")\n",
    "# plt.scatter(X, y) # This might be easier to remember, both functions accomplish the same thing. Try switching the commented one.\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Model Data\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "39fa092a119c03d9d38856cf60f18e93",
     "grade": false,
     "grade_id": "cell-947386f119299c0b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Here you can train a model by manually adjusting the hyperparameter, in this case the polynomial order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d382a6ddd61c33dff14778b69093cd0",
     "grade": false,
     "grade_id": "cell-05370df6a4aec440",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b7fa9d3266b45fc56722f99ed4895f58",
     "grade": false,
     "grade_id": "cell-5a50f9c785eb73b8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "## Change this value and check out the resulting plot\n",
    "order = 1\n",
    "\n",
    "\n",
    "## Don't worry about the below code for now\n",
    "xMin = math.floor(X_model.min())\n",
    "xMax = math.ceil(X_model.min())\n",
    "polynomial_features = PolynomialFeatures(degree=order, include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X_model[:, np.newaxis], y_model)\n",
    "\n",
    "plt.plot(X_model, y_model, marker=\"o\", linestyle=\"None\")\n",
    "plt.plot(np.linspace(xMin,xMax), pipeline.predict(np.linspace(xMin,xMax)[:, np.newaxis]))\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(f\"Order {order}\")\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((-2, 2))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4c9db734f28bffca403c98030e793616",
     "grade": false,
     "grade_id": "cell-eb7c15a5c4a49fb4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "By switching the order we can see the new models generated. At first, using a larger order does better but after we reach a certain point, the model begins to overfit. Let's try to determine the best value for the hyperparemeter. In order to do that, we must select a metric to use to measure the effectiveness of a model. You can select any of the available [regression metrics from sklearn](http://scikit-learn.org/stable/modules/classes.html#regression-metrics) or develop your own.\n",
    "\n",
    "In this example, we will start with the mean squared error. A better model will have a lower value for mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b12441f3ee805ddc4added5b8354da40",
     "grade": false,
     "grade_id": "cell-14046447519273ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "19ab50a5acc3420d9480afb0ea113304",
     "grade": false,
     "grade_id": "cell-c6b0d629575a064c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "orders = np.linspace(1,10,dtype=int)\n",
    "\n",
    "scores = []\n",
    "training_scores = []\n",
    "for order in orders:\n",
    "    polynomial_features = PolynomialFeatures(degree=order, include_bias=False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                             (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X_model[:, np.newaxis], y_model)\n",
    "    training_scores.append(mean_squared_error(y_model, pipeline.predict(X_model[:, np.newaxis])))\n",
    "    scores.append(mean_squared_error(y_valid, pipeline.predict(X_valid[:, np.newaxis])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c5827a14d1fa79f08555b1955e0c3583",
     "grade": false,
     "grade_id": "cell-11fddf677a60b3a9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(orders, training_scores, label=\"Training Score\")\n",
    "plt.plot(orders, scores, label=\"Validation Score\")\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.xlabel(\"Order\")\n",
    "plt.ylabel(\"Mean Squared Error\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "32850ed926795fe0abe7712389a10d14",
     "grade": false,
     "grade_id": "cell-31fd216d885230a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now based on the above figure, select an order and let's see how it performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bf71a021f81fbbd3937947b2219cf057",
     "grade": false,
     "grade_id": "selected_order",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Set the value of selectedOrder to what you think the best hyperparameter value should be\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a3e80252e2d8befb40aa74b0b1b10c34",
     "grade": false,
     "grade_id": "cell-d329d14964b5584d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "polynomial_features = PolynomialFeatures(degree=selectedOrder, include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "\n",
    "# Now we train on all the training data\n",
    "pipeline.fit(X_train[:, np.newaxis], y_train)\n",
    "# And test on the test data\n",
    "test_score = mean_squared_error(y_test, pipeline.predict(X_test[:, np.newaxis]))\n",
    "train_score = scores[selectedOrder-1]\n",
    "\n",
    "print(f\"The selected hyperparameter obtained a score of {train_score} in validation and a score of {test_score} in testing.\")\n",
    "if abs(test_score - train_score) < 0.01 or test_score < train_score:\n",
    "    print(\"Good job!\")\n",
    "else:\n",
    "    print(\"You might want to try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69cb4e03430e87e8998cfea183ae2244",
     "grade": true,
     "grade_id": "test_selected_order",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert abs(test_score - train_score) < 0.01 or test_score < train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a64f084e0f3c0a6c2d88fa8d1b7cd5f",
     "grade": false,
     "grade_id": "cell-66dbab89c710fad5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ed936ab53a1391c5e6af8df699a1dbf5",
     "grade": false,
     "grade_id": "feedback",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def feedback():\n",
    "    \"\"\"Provide feedback on the contents of this exercise\n",
    "    \n",
    "    Returns:\n",
    "        string\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0fc76aeab9893d713d507bf52fdfedfd",
     "grade": true,
     "grade_id": "test_feedback",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iml-exercises",
   "language": "python",
   "name": "iml-exercises"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
