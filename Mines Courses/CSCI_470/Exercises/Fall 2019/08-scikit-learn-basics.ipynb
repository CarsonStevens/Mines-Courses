{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### CSCI 303\n",
    "# Introduction to Data Science\n",
    "<p/>\n",
    "### 8 - Scikit Learn Basics\n",
    "\n",
    "![Scikit learn logo](scikit-learn-logo.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## This Lecture\n",
    "---\n",
    "- Basic usage of the Scikit learn package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "---\n",
    "We'll typically start a notebook from now on with a set of standard imports, and any relevant Jupyter notebook \"magic\" directives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example Problem Setup\n",
    "---\n",
    "We'll continue to use our synthetic problem to illustrate linear regression in Scikit learn:\n",
    "\n",
    "$$ \\begin{align} & f(x) =  3 + 0.5 n - n^2 + 0.15 n^3 \\\\\n",
    "                 & y = f(x) + \\epsilon \n",
    "   \\end{align} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"ground truth\" function\n",
    "def f(x):\n",
    "    return 3 + 0.5 * x - x**2 + 0.15 * x**3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some more functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# ensure repeatability of this notebook \n",
    "# (comment out for new results each run)\n",
    "np.random.seed(12345)\n",
    "\n",
    "# convenience function for generating samples\n",
    "def sample(n, fn, limits, noise=1):\n",
    "    width = limits[1] - limits[0]\n",
    "    x = np.random.random(n) * width + limits[0]\n",
    "    y = fn(x) + np.random.randn(n) * noise\n",
    "    return x, y\n",
    "\n",
    "# there's a scikit learn tool for generating\n",
    "# polynomial features - this will be more useful\n",
    "# when working with multivariate inputs, so we'll\n",
    "# stick with this simpler solution for now\n",
    "def phi(x, k):\n",
    "    return np.array([x ** p for p in range(k)]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression Workflow\n",
    "---\n",
    "- Obtain training samples (data and target)\n",
    "- [optional] Do some initial visualization, statistics\n",
    "- [optional] Preprocess data (generate features, dimensionality reduction)\n",
    "- Initialize a model object\n",
    "- Split data into training and test sets (or use cross validation, more on this another time)\n",
    "- Train the model\n",
    "- Use the trained model to make predictions\n",
    "- Evaluate approximation quality (e.g., examine MSE)\n",
    "- Visualize results\n",
    "- Repeat steps as needed to refine model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obtain Training Samples\n",
    "---\n",
    "Usually this involves getting data from an external source: the internet, your own research, etc.\n",
    "\n",
    "For today, we'll simply sample from our synthetic problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 40\n",
    "\n",
    "# we'll start using scikit learn's names for things\n",
    "data, target = sample(n, f, [-5,5], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initial Visualization\n",
    "---\n",
    "This varies a lot.  One common visualization is scatter plots showing correlations between pairs of inputs and/or the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data, target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Preprocess Data\n",
    "---\n",
    "Our initial visualization suggests non-linearity.  Let's use some polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = phi(data, 5)\n",
    "Phi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize a Model Object\n",
    "---\n",
    "Now we get to some actual Scikit learn code.  \n",
    "\n",
    "There are a bunch of regression models; we're going to use the [linear_model.LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) one.\n",
    "\n",
    "The basic process of obtaining a model, training, and then using it for prediction is uniform-ish across learning methods.  Yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_intercept` parameter above defaults to True, but we already generated an intercept term in our design matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Split Data into Training/Test Sets\n",
    "---\n",
    "There's a Scikit learn [function](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Phi, target, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test_size` parameter is used to control what percentage of the data to hold out for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can check to see that our data matrices/vectors are the size expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[:,1], y_train, 'k.', X_test[:,1], y_test, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the Model\n",
    "---\n",
    "This is done using the `fit` method of the model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predict (and Visualize)\n",
    "---\n",
    "Let's see what we got:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-5, 5, 0.1)\n",
    "yhat = lr.predict(phi(x, 5))\n",
    "plt.plot(x, yhat, 'r-', data, target, 'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our case, we also know ground truth, so let's add that in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, f(x), 'b-', x, yhat, 'r-', X_train[:,1], y_train, 'k.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluate\n",
    "---\n",
    "Let's compute MSE and RMSE on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = ((y_test - lr.predict(X_test)) ** 2).mean()\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(\"MSE: \", MSE)\n",
    "print(\"RMSE:\", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Refine Model\n",
    "---\n",
    "A lot we could do here!  For now, let's repeat our work on evaluating RMSE for different orders.\n",
    "\n",
    "I have to redo some work from above to get all the powers up to 12..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi = phi(data, 12)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    Phi, target, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now I can just pare down my feature matrices using NumPy's array slicing capabilities.\n",
    "\n",
    "This works somewhat like list slicing, but with multi-dimensional support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Phi.shape)\n",
    "\n",
    "print(Phi[:,:3].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compute RMSEs across a range of orders and find the minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "RMSEs = []\n",
    "orders = range(2,13)\n",
    "for p in orders:\n",
    "    lr.fit(X_train[:,:(p+1)], y_train)\n",
    "    MSE = ((y_test - lr.predict(X_test[:,:(p+1)])) ** 2).mean()\n",
    "    RMSEs.append(np.sqrt(MSE))\n",
    "RMSEs = np.array(RMSEs)\n",
    "plt.plot(orders, RMSEs, 'b-x')\n",
    "plt.plot(orders[RMSEs.argmin()], RMSEs.min(), 'rs')\n",
    "plt.show()\n",
    "print(RMSEs.min(), \"at order\", orders[RMSEs.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train[:,:5], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test[:,:5], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COEFFs = []\n",
    "for p in orders:\n",
    "    lr.fit(X_train[:,:p], y_train)\n",
    "    COEFFs.append(lr.score(X_test[:,:p], y_test))\n",
    "COEFFs = np.array(COEFFs)\n",
    "plt.plot(orders, COEFFs, 'b-x')\n",
    "plt.plot(orders[COEFFs.argmax()], COEFFs.max(), 'rs')\n",
    "plt.show()\n",
    "print(COEFFs.max(), \"at order\", orders[COEFFs.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plt.add_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "livereveal": {
   "height": 768,
   "start_slideshow_at": "selected",
   "theme": "mines",
   "transition": "slide",
   "width": 1024
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
