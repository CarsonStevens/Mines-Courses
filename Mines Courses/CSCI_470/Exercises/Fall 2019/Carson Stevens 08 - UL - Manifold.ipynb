{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"iml-exercises","language":"python","name":"iml-exercises"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"Carson Stevens 08 - UL - Manifold.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"bb8ad13c2802772aebe35f0a5518f3a5","grade":false,"grade_id":"cell-c76eacfadca2d44b","locked":true,"schema_version":1,"solution":false},"id":"E7p9hZ1jYaML","colab_type":"text"},"source":["# Unsupervised Learning - Clustering & Manifolds - Carson Stevens\n","\n","In this exercise we will look at a variety of clustering methods including manifold-based methods.\n","\n","First, we examine Agglomerative Clustering methods."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f167158fcb8a8438bd4b9f0cc9849c27","grade":false,"grade_id":"cell-bdbd73329473e5e4","locked":true,"schema_version":1,"solution":false},"id":"WPuJzYqVYaMR","colab_type":"code","colab":{}},"source":["import numpy as np\n","import scipy as sc\n","import pandas as pd\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import sklearn as sk\n","\n","%matplotlib inline\n","plt.style.use(\"ggplot\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"24997d496a3aa7b842498c2646154078","grade":false,"grade_id":"cell-78cc6acb159043e8","locked":true,"schema_version":1,"solution":false},"id":"LIR83LPMYaMa","colab_type":"code","colab":{}},"source":["from sklearn.datasets import load_iris\n","from scipy.cluster.hierarchy import linkage, dendrogram\n","from sklearn.cluster import AgglomerativeClustering\n","from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score, homogeneity_completeness_v_measure, silhouette_score"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f698bdc7925fac14207dcabb214d72fb","grade":false,"grade_id":"cell-a8f841725476d32d","locked":true,"schema_version":1,"solution":false},"id":"3OdaK6d2YaMf","colab_type":"text"},"source":["We will be using the [iris dataset](https://archive.ics.uci.edu/ml/datasets/iris) for this exercise. Please read through the description of the dataset that follows."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"7f7bf5a35e979cd2db96c7be809ce20f","grade":false,"grade_id":"cell-8d77d666d281a463","locked":true,"schema_version":1,"solution":false},"id":"HRvTDErbYaMh","colab_type":"code","colab":{}},"source":["iris = load_iris()\n","iris_features = iris[\"data\"]\n","iris_targets = iris[\"target\"]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"dbf3b6803c2e9e2760ad72d0cf057264","grade":false,"grade_id":"cell-685d3c300873f39d","locked":true,"schema_version":1,"solution":false},"id":"682do3rlYaMq","colab_type":"code","colab":{}},"source":["print(iris[\"DESCR\"])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"28bff53c0b9553ec31fd0e187de16116","grade":false,"grade_id":"cell-da99b7ac1ee476ac","locked":true,"schema_version":1,"solution":false},"id":"t16wrDLqYaMw","colab_type":"text"},"source":["## Agglomerative Clustering\n","\n","In this portion of the exercise, you will plot the dendrograms when applied to the Iris dataset. To do this, you should use the [linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage) and [dendrogram](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.cluster.hierarchy.dendrogram.html#scipy.cluster.hierarchy.dendrogram) functions."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"e6dc6afc58cae027c933856ba10c3a46","grade":false,"grade_id":"cell-7ba61185fe878a6a","locked":false,"schema_version":1,"solution":true},"id":"JEk-NDdBYaMz","colab_type":"code","colab":{}},"source":["def dendrogram_plotter(features, methods, metric):\n","    \"\"\"Plots a dendrogram for the provided features for every method in methods using the provided metric\n","    \n","    Args:\n","        features (iterable): The features to use in creating the dendrogram\n","        methods (iterable): A list of strings where each one is a valid method to the linkage function\n","        metric (str): A metric for calculating the linkage\n","    \"\"\"\n","    for method in methods:\n","        plt.figure(figsize = (10,6)) # Change the figure size to your liking\n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","        plt.title(f\"{method.title()} Linkage Iris Dataset Dendrogram\")\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"890a3424e7ef3e36e761bccd331ca851","grade":true,"grade_id":"cell-9a3884c6587cb41a","locked":true,"points":5,"schema_version":1,"solution":false},"id":"4eWLA8H2YaM8","colab_type":"code","colab":{}},"source":["dendrogram_plotter(iris_features, [\"average\", \"complete\", \"ward\"], \"euclidean\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f1b4b081901a173c93ce52bf8dea67ca","grade":false,"grade_id":"cell-5f6b28f6dcb25689","locked":true,"schema_version":1,"solution":false},"id":"F0VOcfioYaNF","colab_type":"text"},"source":["In addition to the denrogram for visualization, we will apply a variety of clustering methods to the data. In order to compare their effectiveness we'd like to evaluate them based on the scores we had discussed previously. Next, you will write a function that does just that."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"ae0f617f8632e9d274f47191c51a60ce","grade":false,"grade_id":"cell-1a45df2a94be8038","locked":false,"schema_version":1,"solution":true},"id":"qUXwRDIBYaNI","colab_type":"code","colab":{}},"source":["def clustering_scorer(features, targets, pred):\n","    \"\"\"Calculates all the important clustering scores given a set of features, targets and predictions\n","    \n","    Args:\n","        features (iterable): The input features to the clustering problem\n","        targets (iterable): The targets if this was a classification problem\n","        pred (iterable): The cluster predictions for the data samples\n","    \n","    Returns:\n","        dict: A dictionary with the keys ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', \n","            'V Score', 'Silhouette Score'] and values as the respective scores for the inputs.\n","    \"\"\"\n","    # YOUR CODE HERE\n","    raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"d756e68b7441b7ec220dfb3b28e05c55","grade":false,"grade_id":"cell-aa6112b880f1965c","locked":true,"schema_version":1,"solution":false},"id":"XFONlwpdYaNQ","colab_type":"text"},"source":["To create agglomerative clustering estimators, use [AgglomerativeClustering](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering). It was already imported above.\n","To score the agglomerative clusters, you will want to use the function you wrote above, `clustering_scorer`."]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"897eb9c6629401ce15628a2e6ce3de87","grade":false,"grade_id":"cell-de19bff97996022b","locked":false,"schema_version":1,"solution":true},"id":"9npVejn5YaNT","colab_type":"code","colab":{}},"source":["def agg_clustering_scorer(features, targets, linkages, n_clusters=8):\n","    \"\"\"Calculate the agglomerative clustering scores for a variety of linkage types\n","    \n","    Args:\n","        features (iterable): The input features of the data\n","        targets (iterable): The target classes if this was treated as a classification problem\n","        linkages (iterable): A list of linkage methods to calculate scores for\n","        n_clusters (int, optional): Defaults to 8. The number of clusters to use in the clustering algorithm\n","    \n","    Returns:\n","        iterable: Scores for each linkage method similar to the clustering_scorer method's output\n","    \"\"\"\n","    scores = []\n","    for linkage in linkages:\n","        # YOUR CODE HERE\n","        raise NotImplementedError()\n","    return scores"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"ce00afa1484b25b21e9f30a1692836da","grade":false,"grade_id":"cell-a71411dda344157b","locked":true,"schema_version":1,"solution":false},"id":"cU1odS2pYaNZ","colab_type":"code","colab":{}},"source":["aggScores = agg_clustering_scorer(iris_features, iris_targets, [\"average\", \"complete\", \"ward\"], n_clusters=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"5ecf525fdb70b7bef6a5a87155a2a276","grade":true,"grade_id":"cell-8b0f9e6101ff9856","locked":true,"points":5,"schema_version":1,"solution":false},"id":"J7jwn8BSYaNi","colab_type":"code","colab":{}},"source":["assert len(aggScores) == 3\n","for key in ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', 'V Score', 'Silhouette Score']:\n","    assert key in aggScores[0].keys()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"bf7b37a0a6c4f77fc93a836db3509ae6","grade":false,"grade_id":"cell-bb92f3ce36d92c6a","locked":true,"schema_version":1,"solution":false},"id":"6ZPToQ0rYaNt","colab_type":"text"},"source":["Now let's compare the different linkage metrics and how they perform on clustering this dataset."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"7ada3a39cd52b89a242b91c8fe8059c6","grade":false,"grade_id":"cell-990ec54f29e24135","locked":true,"schema_version":1,"solution":false},"id":"aAYAghYbYaNv","colab_type":"code","colab":{}},"source":["for linkage, score in zip([\"average\", \"complete\", \"ward\"],aggScores):\n","    print(f\"With the {linkage} linkage,\")\n","    print(f\"Adjusted rand score is {score['Adjusted Rand']}\")\n","    print(f\"Adjusted mutual info score is {score['Adjusted Mutual Info']}\")\n","    print(f\"Homogeneity is {score['Homogeneity']}, Completeness is {score['Completeness']}, V score is {score['V Score']}\")\n","    print(f\"Silhouette score is {score['Silhouette Score']}\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"79dc1da0e64fc2d5bdc8d77c55587136","grade":false,"grade_id":"cell-566d434849c56af8","locked":true,"schema_version":1,"solution":false},"id":"ZOQmQZLlYaN1","colab_type":"code","colab":{}},"source":["scoresdf = pd.DataFrame(aggScores, index=[\"average\", \"complete\", \"ward\"]).T # Try removing the .T and see what happens\n","scoresdf.plot(kind=\"barh\")\n","plt.title(\"Clustering scores with various linkage methods\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"d41de0cfd5e81ff1deeffb333bf81f02","grade":false,"grade_id":"cell-9d0b21e5532456ba","locked":true,"schema_version":1,"solution":false},"id":"T0LQBxqYYaN7","colab_type":"text"},"source":["## Spectral Clustering\n","\n","Spectral clustering can present a different perspective on the data by using the manifold in the features if it exists. Generally, we can evaluate the presence of manifold in a dataset by the net improvement of spectral clustering when compared to other methods.\n","You will use the [SpectralClustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html) method in the next section."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"4a4bdcc443cea937dc534b4606e2d550","grade":false,"grade_id":"cell-f4a00fcb17652df6","locked":true,"schema_version":1,"solution":false},"id":"HHxxWFk9YaN8","colab_type":"code","colab":{}},"source":["from sklearn.cluster import SpectralClustering"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"18096129e5d3d9d16b084d4881288d83","grade":false,"grade_id":"cell-fa37244cf09f0bae","locked":false,"schema_version":1,"solution":true},"id":"c6QeT-DYYaOB","colab_type":"code","colab":{}},"source":["# Create a spectral clustering classifier saved as `clf`\n","# Fit clf to the iris data\n","# Predict values for the iris data using clf and save them as spectral_pred\n","# YOUR CODE HERE\n","raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"6b0e98e95db69cedc20f949663a9a682","grade":false,"grade_id":"cell-d36a3c20575bf99b","locked":true,"schema_version":1,"solution":false},"id":"sdUIPFdFYaOG","colab_type":"code","colab":{}},"source":["spectral_scores = clustering_scorer(iris_features, iris_targets, spectral_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"b52b91f47ad3cbd4a1565d9b97ecd1d8","grade":true,"grade_id":"cell-35596289ee109dc3","locked":true,"points":5,"schema_version":1,"solution":false},"id":"1So1HoZEYaOK","colab_type":"code","colab":{}},"source":["for key in ['Adjusted Rand', 'Adjusted Mutual Info', 'Homogeneity', 'Completeness', 'V Score', 'Silhouette Score']:\n","    assert key in spectral_scores.keys()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"714b0708360aac858f08dee8322c299e","grade":true,"grade_id":"cell-7144bc9fd9bb85a4","locked":true,"points":5,"schema_version":1,"solution":false},"id":"knmvpQImYaOP","colab_type":"code","colab":{}},"source":["assert clf.n_clusters == 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"a864a5b9a05b24d2e08fd3b8d7cb4101","grade":false,"grade_id":"cell-83ecaca7fdb1cf82","locked":true,"schema_version":1,"solution":false},"id":"kZrcyzzPYaOU","colab_type":"code","colab":{}},"source":["if len(aggScores) == 3:\n","    aggScores.append(spectral_scores)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f00fd5a403f9d2d66db71d12403b6d38","grade":false,"grade_id":"cell-c0cd3f8243e8a816","locked":true,"schema_version":1,"solution":false},"id":"Trv7vc1NYaOd","colab_type":"code","colab":{}},"source":["scoresdf = pd.DataFrame(aggScores, index=[\"average\", \"complete\", \"ward\", \"spectral\"]) # Try removing the .T and see what happens\n","scoresdf.plot(kind=\"barh\")\n","plt.title(\"Clustering scores with various linkage methods and Spectral Clustering\")\n","plt.xlim(0,1.5)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"c15152c5e0d07513fe03f2dd58679a7f","grade":false,"grade_id":"cell-69fa0ea38ad93872","locked":true,"schema_version":1,"solution":false},"id":"fA0ZtLw0YaOl","colab_type":"text"},"source":["## Clustering Overview\n","\n","The below code is copied from http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html and is there for you to see how different methods work with varying input data. We haven't gone over all these methods and so you can only focus on what we've covered. We will go over some of the other methods in a later lecture.\n","\n","**Notice when spectral clustering performs better than $k$Means or agglomerative clustering.**\n","\n","When we have data in concentric circles or two moons, there is a clear relationship in manifold space. When we have blobs of data, you may find that both approaches perform similarly."]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"1b9c4cde43d0e60c5edc8ef5ee713bc3","grade":false,"grade_id":"cell-8be751081a5734f4","locked":true,"schema_version":1,"solution":false},"id":"FT8b9cozYaOm","colab_type":"code","colab":{}},"source":["import time\n","import warnings\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn import cluster, datasets, mixture\n","from sklearn.neighbors import kneighbors_graph\n","from sklearn.preprocessing import StandardScaler\n","from itertools import cycle, islice\n","\n","np.random.seed(0)\n","\n","# ============\n","# Generate datasets. We choose the size big enough to see the scalability\n","# of the algorithms, but not too big to avoid too long running times\n","# ============\n","n_samples = 1500\n","noisy_circles = datasets.make_circles(n_samples=n_samples, factor=.5,\n","                                      noise=.05)\n","noisy_moons = datasets.make_moons(n_samples=n_samples, noise=.05)\n","blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n","no_structure = np.random.rand(n_samples, 2), None\n","\n","# Anisotropicly distributed data\n","random_state = 170\n","X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n","transformation = [[0.6, -0.6], [-0.4, 0.8]]\n","X_aniso = np.dot(X, transformation)\n","aniso = (X_aniso, y)\n","\n","# blobs with varied variances\n","varied = datasets.make_blobs(n_samples=n_samples,\n","                             cluster_std=[1.0, 2.5, 0.5],\n","                             random_state=random_state)\n","\n","# ============\n","# Set up cluster parameters\n","# ============\n","plt.figure(figsize=(9 * 2 + 3, 12.5))\n","plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n","                    hspace=.01)\n","\n","plot_num = 1\n","\n","default_base = {'quantile': .3,\n","                'eps': .3,\n","                'damping': .9,\n","                'preference': -200,\n","                'n_neighbors': 10,\n","                'n_clusters': 3}\n","\n","datasets = [\n","    (noisy_circles, {'damping': .77, 'preference': -240,\n","                     'quantile': .2, 'n_clusters': 2}),\n","    (noisy_moons, {'damping': .75, 'preference': -220, 'n_clusters': 2}),\n","    (varied, {'eps': .18, 'n_neighbors': 2}),\n","    (aniso, {'eps': .15, 'n_neighbors': 2}),\n","    (blobs, {}),\n","    (no_structure, {})]\n","\n","for i_dataset, (dataset, algo_params) in enumerate(datasets):\n","    # update parameters with dataset-specific values\n","    params = default_base.copy()\n","    params.update(algo_params)\n","\n","    X, y = dataset\n","\n","    # normalize dataset for easier parameter selection\n","    X = StandardScaler().fit_transform(X)\n","\n","    # estimate bandwidth for mean shift\n","    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n","\n","    # connectivity matrix for structured Ward\n","    connectivity = kneighbors_graph(\n","        X, n_neighbors=params['n_neighbors'], include_self=False)\n","    # make connectivity symmetric\n","    connectivity = 0.5 * (connectivity + connectivity.T)\n","\n","    # ============\n","    # Create cluster objects\n","    # ============\n","    ms = cluster.MeanShift(bandwidth=bandwidth, bin_seeding=True)\n","    two_means = cluster.MiniBatchKMeans(n_clusters=params['n_clusters'])\n","    ward = cluster.AgglomerativeClustering(\n","        n_clusters=params['n_clusters'], linkage='ward',\n","        connectivity=connectivity)\n","    spectral = cluster.SpectralClustering(\n","        n_clusters=params['n_clusters'], eigen_solver='arpack',\n","        affinity=\"nearest_neighbors\")\n","    dbscan = cluster.DBSCAN(eps=params['eps'])\n","    affinity_propagation = cluster.AffinityPropagation(\n","        damping=params['damping'], preference=params['preference'])\n","    average_linkage = cluster.AgglomerativeClustering(\n","        linkage=\"average\", affinity=\"cityblock\",\n","        n_clusters=params['n_clusters'], connectivity=connectivity)\n","    birch = cluster.Birch(n_clusters=params['n_clusters'])\n","    gmm = mixture.GaussianMixture(\n","        n_components=params['n_clusters'], covariance_type='full')\n","\n","    clustering_algorithms = (\n","        ('MiniBatchKMeans', two_means),\n","        ('AffinityPropagation', affinity_propagation),\n","        ('MeanShift', ms),\n","        ('SpectralClustering', spectral),\n","        ('Ward', ward),\n","        ('AgglomerativeClustering', average_linkage),\n","        ('DBSCAN', dbscan),\n","        ('Birch', birch),\n","        ('GaussianMixture', gmm)\n","    )\n","\n","    for name, algorithm in clustering_algorithms:\n","        t0 = time.time()\n","\n","        # catch warnings related to kneighbors_graph\n","        with warnings.catch_warnings():\n","            warnings.filterwarnings(\n","                \"ignore\",\n","                message=\"the number of connected components of the \" +\n","                \"connectivity matrix is [0-9]{1,2}\" +\n","                \" > 1. Completing it to avoid stopping the tree early.\",\n","                category=UserWarning)\n","            warnings.filterwarnings(\n","                \"ignore\",\n","                message=\"Graph is not fully connected, spectral embedding\" +\n","                \" may not work as expected.\",\n","                category=UserWarning)\n","            algorithm.fit(X)\n","\n","        t1 = time.time()\n","        if hasattr(algorithm, 'labels_'):\n","            y_pred = algorithm.labels_.astype(np.int)\n","        else:\n","            y_pred = algorithm.predict(X)\n","\n","        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n","        if i_dataset == 0:\n","            plt.title(name, size=18)\n","\n","        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n","                                             '#f781bf', '#a65628', '#984ea3',\n","                                             '#999999', '#e41a1c', '#dede00']),\n","                                      int(max(y_pred) + 1))))\n","        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n","\n","        plt.xlim(-2.5, 2.5)\n","        plt.ylim(-2.5, 2.5)\n","        plt.xticks(())\n","        plt.yticks(())\n","        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n","                 transform=plt.gca().transAxes, size=15,\n","                 horizontalalignment='right')\n","        plot_num += 1\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"95e2b11a88404fb6cf097d62d5cd99cc","grade":false,"grade_id":"cell-8c870868142b024c","locked":true,"schema_version":1,"solution":false},"id":"TNUpZW0PYaOp","colab_type":"text"},"source":["## Feedback"]},{"cell_type":"code","metadata":{"deletable":false,"nbgrader":{"checksum":"ed936ab53a1391c5e6af8df699a1dbf5","grade":false,"grade_id":"feedback","locked":false,"schema_version":1,"solution":true},"id":"BVtfICXJYaOq","colab_type":"code","colab":{}},"source":["def feedback():\n","    \"\"\"Provide feedback on the contents of this exercise\n","    \n","    Returns:\n","        string\n","    \"\"\"\n","    # YOUR CODE HERE\n","    raise NotImplementedError()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"deletable":false,"editable":false,"nbgrader":{"checksum":"f39f6185a54850c2f1f9b5b2a17b7543","grade":true,"grade_id":"feedback-tests","locked":true,"points":0,"schema_version":1,"solution":false},"id":"9NXazuCVYaOu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}